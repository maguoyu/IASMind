---
title: n8n 工作流开发规范
alwaysApply: true
---

# n8n 工作流开发规范

## 版本信息

- n8n 版本: **1.116.2**
- 使用最新的节点版本和功能
- 关注版本更新日志中的breaking changes

## 工作流设计原则

- 工作流应具有清晰的命名，描述其功能和用途
- 每个工作流聚焦单一职责，避免过度复杂
- 使用节点注释和便签说明关键逻辑
- 合理使用子工作流（Execute Workflow）拆分复杂流程
- 保持工作流的可维护性和可读性

## 节点命名规范

- 节点名称应描述其具体功能，而非仅使用默认名称
- 使用中文命名节点以提高团队可读性
- 关键节点添加注释说明其作用和配置
- 示例命名：
  - ❌ "HTTP Request"
  - ✅ "调用第三方API获取用户信息"
  - ❌ "Code"
  - ✅ "数据转换-格式化订单信息"

## 表达式和数据处理

### 表达式语法

- 使用 `{{ }}` 包裹表达式
- 访问前置节点数据：`{{ $node["节点名称"].json }}`
- 访问输入数据：`{{ $input.item.json }}`
- 访问所有输入：`{{ $input.all() }}`
- 环境变量：`{{ $env.VARIABLE_NAME }}`
- 工作流静态数据：`{{ $workflow.staticData }}`

### 数据转换最佳实践

- 优先使用内置节点（Edit Fields, Set）进行数据转换
- 对于复杂逻辑，使用 Code 节点（JavaScript）
- 在 Code 节点中使用清晰的变量名和注释
- 返回数据应保持一致的结构

示例 Code 节点：
```javascript
// 处理输入数据并转换格式
const inputData = $input.all();

const transformedData = inputData.map(item => {
  const data = item.json;
  
  return {
    userId: data.id,
    userName: data.name,
    email: data.email.toLowerCase(),
    createdAt: new Date(data.timestamp).toISOString()
  };
});

return transformedData;
```

## 错误处理

- 为关键节点启用"继续出错时"（Continue on Fail）选项
- 使用 Error Trigger 捕获工作流错误
- 在 IF 节点中验证数据完整性
- 使用 Stop and Error 节点处理业务逻辑错误
- 添加错误通知机制（如发送告警消息）

错误处理结构示例：
```
[HTTP Request] -> [IF判断响应状态] -> [成功路径]
                                    -> [失败路径] -> [记录错误] -> [发送通知]
```

## 触发器使用

### Webhook 触发器

- 使用唯一的 Webhook 路径名
- 在生产环境使用 Production URL
- 启用身份验证（Basic Auth 或 Header Auth）
- 验证 Webhook 请求数据格式
- 返回适当的响应状态码和消息

### 定时触发器（Cron/Schedule）

- 使用 Cron 表达式设置精确的执行时间
- 避免在高峰时段执行资源密集型工作流
- 为长时间运行的工作流设置超时
- 使用时区感知的时间配置

## HTTP 请求规范

- 明确指定请求方法（GET, POST, PUT, DELETE）
- 使用凭证存储敏感信息（API密钥、令牌）
- 设置合理的超时时间（默认300秒）
- 处理分页和限流
- 使用请求头传递必要的元数据

HTTP 节点配置示例：
```json
{
  "method": "POST",
  "url": "https://api.example.com/users",
  "authentication": "predefinedCredentialType",
  "options": {
    "timeout": 30000,
    "retry": {
      "enabled": true,
      "maxRetries": 3
    }
  }
}
```

## 数据库操作

- 使用参数化查询防止 SQL 注入
- 对于大量数据，使用批量操作
- 合理使用事务保证数据一致性
- 添加数据库连接超时配置
- 使用连接池提高性能

## 循环和批处理

- 使用 Loop Over Items 处理数组数据
- 对于大数据集，使用分批处理（Batch）
- 在循环中添加错误处理避免整体失败
- 考虑使用 Split In Batches 节点处理大型数据集
- 避免无限循环，设置最大迭代次数

## 凭证管理

- 所有敏感信息使用凭证（Credentials）存储
- 不要在工作流中硬编码密钥、密码、令牌
- 使用环境变量配合凭证管理不同环境
- 定期轮换和更新凭证
- 遵循最小权限原则

## 性能优化

- 减少不必要的节点和连接
- 使用 Filter 节点提前过滤数据
- 并行处理独立任务
- 避免在循环中执行昂贵操作
- 使用缓存减少重复请求
- 监控工作流执行时间和资源使用

## 测试和调试

- 使用手动触发器测试工作流
- 利用"执行节点"功能单独测试节点
- 检查每个节点的输入输出数据
- 使用示例数据测试边界情况
- 在生产部署前进行完整的端到端测试

## 版本控制和文档

- 导出工作流 JSON 文件进行版本控制
- 在工作流描述中记录：
  - 工作流目的
  - 依赖的凭证和外部服务
  - 触发条件
  - 更新日志
- 关键配置使用注释说明
- 保持工作流定期备份

## AI 节点集成规范

### OpenAI / AI 节点使用

- 设置合理的 token 限制
- 使用 system prompt 定义 AI 行为
- 处理 AI 响应的不确定性
- 实现重试机制处理 API 限流
- 记录 AI 请求和响应用于调试

### AI Chain 构建

- 使用 AI Agent 节点构建复杂对话流程
- 明确定义工具（Tools）和其功能
- 实现适当的对话历史管理
- 添加回退机制处理无法理解的输入

## SSE（Server-Sent Events）支持

- 使用 Webhook 响应配置 SSE 流式输出
- 设置正确的响应头：
  ```
  Content-Type: text/event-stream
  Cache-Control: no-cache
  Connection: keep-alive
  ```
- 实现心跳机制保持连接
- 正确处理客户端断开连接

## 安全最佳实践

- 验证所有外部输入
- 使用 HTTPS 进行所有外部通信
- 实施适当的身份验证和授权
- 不在日志中记录敏感信息
- 定期审查工作流访问权限
- 使用 n8n 的权限管理控制访问

## 常用节点组合模式

### API 调用模式
```
[Webhook] -> [验证请求] -> [HTTP Request] -> [数据转换] -> [响应]
```

### 数据处理管道
```
[触发器] -> [获取数据] -> [过滤] -> [转换] -> [聚合] -> [存储]
```

### 错误处理模式
```
[操作节点] -> [IF判断成功] -> [成功处理]
                         -> [失败处理] -> [通知]
```

### 批量处理模式
```
[触发器] -> [Split In Batches] -> [Loop Over Items] -> [处理单项] -> [聚合结果]
```

## 监控和维护

- 定期检查工作流执行历史
- 设置执行失败告警
- 监控工作流性能指标
- 清理过期的执行数据
- 更新节点到最新版本
- 审查和优化慢速工作流
