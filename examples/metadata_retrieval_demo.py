#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å…ƒæ•°æ®æ£€ç´¢æµç¨‹æ¼”ç¤º
å±•ç¤ºä»ç”¨æˆ·è‡ªç„¶è¯­è¨€è¾“å…¥åˆ°è·å–ç›¸å…³å…ƒæ•°æ®çš„å®Œæ•´è¿‡ç¨‹
"""

import asyncio
import json
from typing import Dict, List, Any

class MetadataRetrievalDemo:
    """å…ƒæ•°æ®æ£€ç´¢æ¼”ç¤ºç±»"""
    
    def __init__(self):
        # æ¨¡æ‹Ÿçš„å‘é‡åŒ–å…ƒæ•°æ®åº“
        self.metadata_vectors = [
            {
                "content": "æ•°æ®è¡¨: vehicle_refuel | ä¸šåŠ¡ç”¨é€”: è½¦è¾†åŠ æ²¹è®°å½•ç®¡ç† | ä¸šåŠ¡é¢†åŸŸ: è½¦è¾†ç®¡ç† | ä¸»é”®: refuel_id(åŠ æ²¹è®°å½•ID) | æ ¸å¿ƒå­—æ®µ: vehicle_id(è½¦è¾†ID), refuel_volume(åŠ æ²¹é‡ï¼ˆå‡ï¼‰), driver_id(å¸æœºID) | é‡‘é¢å­—æ®µ: refuel_amount(åŠ æ²¹é‡‘é¢) | æ—¶é—´å­—æ®µ: refuel_time(åŠ æ²¹æ—¶é—´), created_at() | çŠ¶æ€å­—æ®µ: status(è®°å½•çŠ¶æ€) | å…³è”å­—æ®µ: vehicle_id(), driver_id(), station_id() | å…³è”è¡¨: vehicle, driver, gas_station | æŸ¥è¯¢ç‰¹æ€§: æ”¯æŒæ—¶é—´èŒƒå›´æŸ¥è¯¢, æ”¯æŒé‡‘é¢ç»Ÿè®¡, æ”¯æŒçŠ¶æ€ç­›é€‰, æ”¯æŒå¤šè¡¨å…³è”, åŒ…å«ä¸šåŠ¡å±æ€§ | SQLæç¤º: å¸¸ç”¨å­—æ®µ: refuel_id, vehicle_id, refuel_volume, çŠ¶æ€ç­›é€‰: WHERE status = ?, æ—¶é—´ç­›é€‰: WHERE refuel_time BETWEEN ? AND ?",
                "metadata": {
                    "datasource_id": "ds_001",
                    "item_type": "table",
                    "table_name": "vehicle_refuel",
                    "business_domain": "è½¦è¾†ç®¡ç†",
                    "has_relationships": True,
                    "field_count": 8
                },
                "vector_similarity": 0.95
            },
            {
                "content": "æ•°æ®è¡¨: vehicle | ä¸šåŠ¡ç”¨é€”: è½¦è¾†åŸºæœ¬ä¿¡æ¯ç®¡ç† | ä¸šåŠ¡é¢†åŸŸ: è½¦è¾†ç®¡ç† | ä¸»é”®: vehicle_id(è½¦è¾†å”¯ä¸€æ ‡è¯†) | æ ¸å¿ƒå­—æ®µ: vehicle_number(è½¦ç‰Œå·), vehicle_type(è½¦è¾†ç±»å‹), brand(å“ç‰Œ), model(å‹å·) | æ—¶é—´å­—æ®µ: purchase_date(è´­ä¹°æ—¥æœŸ), created_at() | çŠ¶æ€å­—æ®µ: status(è½¦è¾†çŠ¶æ€) | å…³è”å­—æ®µ: driver_id() | å…³è”è¡¨: vehicle_refuel, driver, vehicle_maintenance | æŸ¥è¯¢ç‰¹æ€§: æ”¯æŒçŠ¶æ€ç­›é€‰, æ”¯æŒå¤šè¡¨å…³è”, åŒ…å«ä¸šåŠ¡å±æ€§",
                "metadata": {
                    "datasource_id": "ds_001", 
                    "item_type": "table",
                    "table_name": "vehicle",
                    "business_domain": "è½¦è¾†ç®¡ç†",
                    "has_relationships": True,
                    "field_count": 10
                },
                "vector_similarity": 0.88
            },
            {
                "content": "æ•°æ®è¡¨: driver | ä¸šåŠ¡ç”¨é€”: å¸æœºä¿¡æ¯ç®¡ç† | ä¸šåŠ¡é¢†åŸŸ: è½¦è¾†ç®¡ç† | ä¸»é”®: driver_id(å¸æœºå”¯ä¸€æ ‡è¯†) | æ ¸å¿ƒå­—æ®µ: driver_name(å¸æœºå§“å), phone(è”ç³»ç”µè¯), license_number(é©¾ç…§å·ç ), driver_level(é©¾é©¶ç­‰çº§) | æ—¶é—´å­—æ®µ: hire_date(å…¥èŒæ—¥æœŸ), created_at() | çŠ¶æ€å­—æ®µ: status(å¸æœºçŠ¶æ€) | å…³è”è¡¨: vehicle, vehicle_refuel | æŸ¥è¯¢ç‰¹æ€§: æ”¯æŒçŠ¶æ€ç­›é€‰, æ”¯æŒå¤šè¡¨å…³è”, åŒ…å«ä¸šåŠ¡å±æ€§",
                "metadata": {
                    "datasource_id": "ds_001",
                    "item_type": "table", 
                    "table_name": "driver",
                    "business_domain": "è½¦è¾†ç®¡ç†",
                    "has_relationships": True,
                    "field_count": 8
                },
                "vector_similarity": 0.82
            },
            {
                "content": "æ•°æ®è¡¨: gas_station | ä¸šåŠ¡ç”¨é€”: åŠ æ²¹ç«™ä¿¡æ¯ç®¡ç† | ä¸šåŠ¡é¢†åŸŸ: è½¦è¾†ç®¡ç† | ä¸»é”®: station_id(åŠ æ²¹ç«™ID) | æ ¸å¿ƒå­—æ®µ: station_name(åŠ æ²¹ç«™åç§°), address(åœ°å€), oil_types(æ²¹å“ç±»å‹) | å…³è”è¡¨: vehicle_refuel | æŸ¥è¯¢ç‰¹æ€§: æ”¯æŒå¤šè¡¨å…³è”",
                "metadata": {
                    "datasource_id": "ds_001",
                    "item_type": "table",
                    "table_name": "gas_station", 
                    "business_domain": "è½¦è¾†ç®¡ç†",
                    "has_relationships": True,
                    "field_count": 6
                },
                "vector_similarity": 0.75
            },
            {
                "content": "æ•°æ®è¡¨: user | ä¸šåŠ¡ç”¨é€”: ç”¨æˆ·åŸºæœ¬ä¿¡æ¯ | ä¸šåŠ¡é¢†åŸŸ: ç”¨æˆ·ç®¡ç† | ä¸»é”®: user_id(ç”¨æˆ·ID) | æ ¸å¿ƒå­—æ®µ: username(ç”¨æˆ·å), email(é‚®ç®±), phone(æ‰‹æœºå·) | æ—¶é—´å­—æ®µ: created_at(åˆ›å»ºæ—¶é—´) | çŠ¶æ€å­—æ®µ: status(ç”¨æˆ·çŠ¶æ€) | å…³è”è¡¨: order, user_profile",
                "metadata": {
                    "datasource_id": "ds_001",
                    "item_type": "table",
                    "table_name": "user",
                    "business_domain": "ç”¨æˆ·ç®¡ç†", 
                    "has_relationships": True,
                    "field_count": 8
                },
                "vector_similarity": 0.45
            }
        ]
        
        # æ¨¡æ‹Ÿè¡¨å…³ç³»å›¾
        self.table_relationships = {
            "vehicle_refuel": {
                "references": ["vehicle", "driver", "gas_station"],
                "referenced_by": [],
                "related_tables": ["vehicle", "driver", "gas_station"]
            },
            "vehicle": {
                "references": [],
                "referenced_by": ["vehicle_refuel"],
                "related_tables": ["vehicle_refuel", "driver"]
            },
            "driver": {
                "references": [],
                "referenced_by": ["vehicle_refuel"], 
                "related_tables": ["vehicle_refuel", "vehicle"]
            },
            "gas_station": {
                "references": [],
                "referenced_by": ["vehicle_refuel"],
                "related_tables": ["vehicle_refuel"]
            }
        }
        
        # ä¸šåŠ¡å®ä½“è¯†åˆ«å™¨
        self.domain_keywords = {
            "è½¦è¾†ç®¡ç†": {
                "keywords": ["è½¦è¾†", "vehicle", "æ±½è½¦", "è´§è½¦", "å¸æœº", "driver", "åŠ æ²¹", "refuel"],
                "related_concepts": ["ç»´ä¿®", "ä¿é™©", "è¿è¾“"]
            },
            "ç”¨æˆ·ç®¡ç†": {
                "keywords": ["ç”¨æˆ·", "user", "å®¢æˆ·", "customer"],
                "related_concepts": ["æƒé™", "è§’è‰²", "ç™»å½•"]
            }
        }
    
    def preprocess_query(self, user_input: str) -> str:
        """ç¬¬1é˜¶æ®µï¼šæŸ¥è¯¢é¢„å¤„ç†"""
        print(f"ğŸ” ç¬¬1é˜¶æ®µï¼šæŸ¥è¯¢é¢„å¤„ç†")
        print(f"   åŸå§‹è¾“å…¥: '{user_input}'")
        
        # æ ‡å‡†åŒ–å¤„ç†
        cleaned_query = user_input.strip()
        replacements = {
            "æŸ¥è¯¢": "",
            "è·å–": "",
            "è¯·": "",
            "å¸®æˆ‘": "",
            "å’Œ": " "
        }
        
        for old, new in replacements.items():
            cleaned_query = cleaned_query.replace(old, new)
        
        cleaned_query = cleaned_query.strip()
        print(f"   é¢„å¤„ç†å: '{cleaned_query}'")
        return cleaned_query
    
    def analyze_query_intent(self, query: str) -> Dict[str, Any]:
        """ç¬¬2é˜¶æ®µï¼šæ„å›¾åˆ†æä¸å®ä½“è¯†åˆ«"""
        print(f"\nğŸ§  ç¬¬2é˜¶æ®µï¼šæ„å›¾åˆ†æä¸å®ä½“è¯†åˆ«")
        
        # è¯†åˆ«ä¸šåŠ¡å®ä½“
        entities = []
        for domain, info in self.domain_keywords.items():
            if any(keyword in query for keyword in info["keywords"]):
                entities.append(domain)
        
        # è¯†åˆ«æ„å›¾ç±»å‹
        intent_types = []
        if any(word in query for word in ["ç»Ÿè®¡", "åˆ†æ", "æ±‡æ€»", "æŠ¥è¡¨"]):
            intent_types.append("ç»Ÿè®¡åˆ†æ")
        if any(word in query for word in ["è¯¦ç»†", "æ˜ç»†", "ä¿¡æ¯", "è®°å½•"]):
            intent_types.append("è¯¦ç»†æŸ¥è¯¢")
        if any(word in query for word in ["å…³è”", "ç›¸å…³", "å’Œ"]):
            intent_types.append("å…³è”æŸ¥è¯¢")
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦å…³è”
        requires_relations = any(word in query for word in ["å…³è”", "ç›¸å…³", "ç»Ÿè®¡", "åˆ†æ", "å’Œ"])
        
        # åˆ¤æ–­å¤æ‚åº¦
        if len(entities) > 1 or requires_relations:
            complexity_level = "complex"
        elif intent_types:
            complexity_level = "medium"
        else:
            complexity_level = "simple"
        
        intent = {
            "entities": entities,
            "intent_types": intent_types,
            "requires_relations": requires_relations,
            "complexity_level": complexity_level
        }
        
        print(f"   è¯†åˆ«å®ä½“: {entities}")
        print(f"   æ„å›¾ç±»å‹: {intent_types}")
        print(f"   éœ€è¦å…³è”: {requires_relations}")
        print(f"   å¤æ‚åº¦çº§åˆ«: {complexity_level}")
        
        return intent
    
    def basic_vector_search(self, query: str, limit: int = 5) -> List[Dict]:
        """åŸºç¡€å‘é‡æ£€ç´¢"""
        print(f"\n   ğŸ“Š åŸºç¡€å‘é‡æ£€ç´¢ (é™åˆ¶: {limit})")
        
        # æ¨¡æ‹Ÿå‘é‡ç›¸ä¼¼åº¦è®¡ç®—
        results = []
        query_words = set(query.lower().split())
        
        for item in self.metadata_vectors:
            content_words = set(item["content"].lower().split())
            
            # è®¡ç®—è¯æ±‡é‡å åº¦
            intersection = len(query_words & content_words)
            union = len(query_words | content_words)
            jaccard_score = intersection / union if union > 0 else 0
            
            # ç»“åˆé¢„è®¾çš„å‘é‡ç›¸ä¼¼åº¦
            final_score = item["vector_similarity"] * 0.7 + jaccard_score * 0.3
            
            if jaccard_score > 0:  # æœ‰å…³é”®è¯é‡å æ‰è€ƒè™‘
                results.append({
                    **item,
                    "score": final_score
                })
        
        # æŒ‰åˆ†æ•°æ’åº
        results = sorted(results, key=lambda x: x["score"], reverse=True)[:limit]
        
        for i, result in enumerate(results):
            print(f"     {i+1}. {result['metadata']['table_name']} (åˆ†æ•°: {result['score']:.3f})")
        
        return results
    
    def expand_by_relations(self, base_results: List[Dict], intent: Dict) -> List[Dict]:
        """å…³ç³»æ„ŸçŸ¥æ‰©å±•æ£€ç´¢"""
        print(f"\n   ğŸ”— å…³ç³»æ„ŸçŸ¥æ‰©å±•æ£€ç´¢")
        
        if not intent["requires_relations"]:
            print("     è·³è¿‡å…³ç³»æ‰©å±•ï¼ˆä¸éœ€è¦å…³è”æŸ¥è¯¢ï¼‰")
            return []
        
        # è·å–ç§å­è¡¨
        seed_tables = set()
        for result in base_results:
            table_name = result["metadata"]["table_name"]
            seed_tables.add(table_name)
        
        print(f"     ç§å­è¡¨: {list(seed_tables)}")
        
        # è·å–å…³è”è¡¨
        related_tables = set()
        depth = 2 if intent["complexity_level"] == "complex" else 1
        print(f"     å…³ç³»æ·±åº¦: {depth}")
        
        for table in seed_tables:
            if table in self.table_relationships:
                related = self.table_relationships[table]["related_tables"]
                related_tables.update(related)
        
        related_tables -= seed_tables  # ç§»é™¤å·²æœ‰çš„è¡¨
        print(f"     å‘ç°å…³è”è¡¨: {list(related_tables)}")
        
        # æ£€ç´¢å…³è”è¡¨çš„å…ƒæ•°æ®
        relation_results = []
        for table_name in related_tables:
            for item in self.metadata_vectors:
                if item["metadata"]["table_name"] == table_name:
                    relation_results.append({
                        **item,
                        "score": item["vector_similarity"] * 0.8  # å…³è”è¡¨æƒé‡ç¨ä½
                    })
                    break
        
        return relation_results
    
    def expand_by_keywords(self, query: str, intent: Dict) -> List[Dict]:
        """å…³é”®è¯æ‰©å±•æ£€ç´¢"""
        print(f"\n   ğŸ”¤ å…³é”®è¯æ‰©å±•æ£€ç´¢")
        
        expanded_queries = []
        
        # åŸºäºè¯†åˆ«çš„å®ä½“ç”Ÿæˆæ‰©å±•æŸ¥è¯¢
        for entity in intent["entities"]:
            entity_keywords = self.domain_keywords.get(entity, {})
            for keyword in entity_keywords.get("keywords", [])[:2]:
                if keyword not in query:
                    expanded_query = f"{query} {keyword}"
                    expanded_queries.append(expanded_query)
        
        print(f"     æ‰©å±•æŸ¥è¯¢: {expanded_queries}")
        
        # æ‰§è¡Œæ‰©å±•æ£€ç´¢
        keyword_results = []
        for exp_query in expanded_queries[:2]:  # é™åˆ¶æ‰©å±•æŸ¥è¯¢æ•°é‡
            results = self.basic_vector_search(exp_query, 2)
            keyword_results.extend(results)
        
        return keyword_results
    
    def smart_merge_results(self, base_results: List[Dict], relation_results: List[Dict], 
                          keyword_results: List[Dict], query: str, intent: Dict) -> List[Dict]:
        """æ™ºèƒ½åˆå¹¶ç»“æœ"""
        print(f"\nğŸ¯ ç¬¬4é˜¶æ®µï¼šç»“æœæ™ºèƒ½åˆå¹¶")
        
        all_results = base_results + relation_results + keyword_results
        
        # æŒ‰è¡¨åå»é‡
        seen_tables = set()
        merged = []
        
        for result in all_results:
            table_name = result["metadata"]["table_name"]
            if table_name not in seen_tables:
                seen_tables.add(table_name)
                
                # é‡æ–°è®¡ç®—ç»¼åˆç›¸å…³æ€§åˆ†æ•°
                final_score = self.calculate_comprehensive_score(result, query, intent)
                result["final_score"] = final_score
                merged.append(result)
        
        # æŒ‰ç»¼åˆåˆ†æ•°æ’åº
        merged = sorted(merged, key=lambda x: x["final_score"], reverse=True)
        
        print(f"   åˆå¹¶åçš„ç»“æœ ({len(merged)} ä¸ªè¡¨):")
        for i, result in enumerate(merged):
            table_name = result["metadata"]["table_name"]
            score = result["final_score"]
            domain = result["metadata"]["business_domain"]
            print(f"     {i+1}. {table_name} - {domain} (ç»¼åˆåˆ†æ•°: {score:.3f})")
        
        return merged
    
    def calculate_comprehensive_score(self, result: Dict, query: str, intent: Dict) -> float:
        """è®¡ç®—ç»¼åˆç›¸å…³æ€§åˆ†æ•°"""
        base_score = result.get("score", 0.5)
        content = result["content"]
        table_name = result["metadata"]["table_name"]
        
        # åŸºç¡€åˆ†æ•°æƒé‡ (40%)
        score = base_score * 0.4
        
        # è¡¨ååŒ¹é…åº¦ (20%)
        query_words = set(query.lower().split())
        if any(word in table_name.lower() for word in query_words):
            score += 0.2
        
        # ä¸šåŠ¡å®ä½“åŒ¹é…åº¦ (30%)
        entity_match_count = 0
        for entity in intent["entities"]:
            if entity in content:
                entity_match_count += 1
        
        if intent["entities"]:
            entity_score = entity_match_count / len(intent["entities"])
            score += entity_score * 0.3
        
        # å†…å®¹è¯æ±‡é‡å åº¦ (10%)
        content_words = set(content.lower().split())
        intersection = len(query_words & content_words)
        union = len(query_words | content_words)
        if union > 0:
            jaccard_score = intersection / union
            score += jaccard_score * 0.1
        
        return min(score, 1.0)
    
    def format_metadata_output(self, results: List[Dict], query: str) -> Dict[str, Any]:
        """ç¬¬5é˜¶æ®µï¼šå…ƒæ•°æ®ç»“æ„åŒ–è¾“å‡º"""
        print(f"\nğŸ“‹ ç¬¬5é˜¶æ®µï¼šå…ƒæ•°æ®ç»“æ„åŒ–è¾“å‡º")
        
        formatted_results = []
        for result in results:
            formatted_result = {
                "content": result["content"],
                "score": result["final_score"],
                "datasource_id": result["metadata"]["datasource_id"],
                "item_type": result["metadata"]["item_type"],
                "table_name": result["metadata"]["table_name"],
                "business_domain": result["metadata"]["business_domain"],
                "raw_data": {
                    "table_name": result["metadata"]["table_name"],
                    "business_domain": result["metadata"]["business_domain"],
                    "field_count": result["metadata"]["field_count"],
                    "has_relationships": result["metadata"]["has_relationships"]
                }
            }
            formatted_results.append(formatted_result)
        
        output = {
            "success": True,
            "query": query,
            "results": formatted_results,
            "count": len(formatted_results),
            "message": f"æ‰¾åˆ° {len(formatted_results)} ä¸ªç›¸å…³ç»“æœ"
        }
        
        print(f"   æ ¼å¼åŒ–å®Œæˆï¼Œè¿”å› {len(formatted_results)} ä¸ªç»“æœ")
        return output
    
    async def retrieve_metadata(self, user_input: str) -> Dict[str, Any]:
        """å®Œæ•´çš„å…ƒæ•°æ®æ£€ç´¢æµç¨‹"""
        print(f"ğŸš€ å¼€å§‹å…ƒæ•°æ®æ£€ç´¢æµç¨‹")
        print(f"=" * 60)
        
        # ç¬¬1é˜¶æ®µï¼šæŸ¥è¯¢é¢„å¤„ç†
        cleaned_query = self.preprocess_query(user_input)
        
        # ç¬¬2é˜¶æ®µï¼šæ„å›¾åˆ†æä¸å®ä½“è¯†åˆ«
        intent = self.analyze_query_intent(cleaned_query)
        
        # ç¬¬3é˜¶æ®µï¼šå¤šç­–ç•¥å‘é‡æ£€ç´¢
        print(f"\nğŸ” ç¬¬3é˜¶æ®µï¼šå¤šç­–ç•¥å‘é‡æ£€ç´¢")
        
        # 3.1 åŸºç¡€å‘é‡æ£€ç´¢
        base_results = self.basic_vector_search(cleaned_query, 3)
        
        # 3.2 å…³ç³»æ„ŸçŸ¥æ‰©å±•æ£€ç´¢
        relation_results = self.expand_by_relations(base_results, intent)
        
        # 3.3 å…³é”®è¯æ‰©å±•æ£€ç´¢
        keyword_results = self.expand_by_keywords(cleaned_query, intent)
        
        # ç¬¬4é˜¶æ®µï¼šç»“æœæ™ºèƒ½åˆå¹¶
        merged_results = self.smart_merge_results(
            base_results, relation_results, keyword_results, cleaned_query, intent
        )
        
        # ç¬¬5é˜¶æ®µï¼šå…ƒæ•°æ®ç»“æ„åŒ–è¾“å‡º
        final_output = self.format_metadata_output(merged_results, user_input)
        
        print(f"\nâœ… æ£€ç´¢æµç¨‹å®Œæˆï¼")
        print(f"=" * 60)
        
        return final_output

async def main():
    """æ¼”ç¤ºä¸»å‡½æ•°"""
    demo = MetadataRetrievalDemo()
    
    # æµ‹è¯•ç”¨ä¾‹
    test_queries = [
        "æŸ¥è¯¢è½¦è¾†çš„åŠ æ²¹è®°å½•å’Œå¸æœºä¿¡æ¯",
        "è½¦è¾†åŠ æ²¹ç»Ÿè®¡", 
        "ç”¨æˆ·ä¿¡æ¯",
        "è½¦è¾†ç»´ä¿®è®°å½•"
    ]
    
    for i, query in enumerate(test_queries, 1):
        print(f"\n{'='*20} æµ‹è¯•ç”¨ä¾‹ {i} {'='*20}")
        print(f"ç”¨æˆ·è¾“å…¥: '{query}'")
        print()
        
        result = await demo.retrieve_metadata(query)
        
        print(f"\nğŸ“Š æœ€ç»ˆæ£€ç´¢ç»“æœ:")
        print(f"æŸ¥è¯¢: {result['query']}")
        print(f"ç»“æœæ•°é‡: {result['count']}")
        print(f"ç›¸å…³è¡¨:")
        for j, res in enumerate(result['results'], 1):
            print(f"  {j}. {res['table_name']} ({res['business_domain']}) - ç›¸å…³æ€§: {res['score']:.3f}")
        
        print(f"\n" + "="*60)

if __name__ == "__main__":
    asyncio.run(main()) 