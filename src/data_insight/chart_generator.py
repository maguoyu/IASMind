# Copyright (c) 2025 Bytedance Ltd. and/or its affiliates
# SPDX-License-Identifier: MIT

"""
æœ¬åœ°æ•°æ®æ´å¯Ÿå’Œå›¾è¡¨ç”Ÿæˆæ¨¡å—
åŸºäºEChartsçš„æ•°æ®å¯è§†åŒ–å®ç°
"""

import json
import logging
import pandas as pd
import numpy as np
from typing import Any, Dict, List, Optional, Tuple, Union
from datetime import datetime

from src.llms.llm import get_llm_by_type
from src.data_insight.data_insight_framework import DataInsightFramework

logger = logging.getLogger(__name__)

def clean_numpy_types(obj: Any) -> Any:
    """é€’å½’æ¸…ç†numpyç±»å‹ï¼Œè½¬æ¢ä¸ºPythonåŸç”Ÿç±»å‹ä»¥ä¾¿åºåˆ—åŒ–"""
    if isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.bool_):
        return bool(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {key: clean_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [clean_numpy_types(item) for item in obj]
    elif isinstance(obj, tuple):
        return tuple(clean_numpy_types(item) for item in obj)
    else:
        return obj

class LocalChartGenerator:
    """æœ¬åœ°å›¾è¡¨ç”Ÿæˆå™¨ï¼Œä½¿ç”¨EChartsè§„èŒƒ"""
    
    def __init__(self):
        self.supported_chart_types = [
            'bar', 'line', 'pie', 'scatter', 'area', 'funnel', 'radar'
        ]
    
    async def generate_chart(
        self,
        data: Any,
        data_type: str,
        user_prompt: Optional[str] = None,
        enable_insights: bool = True,
        use_llm: bool = False
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆå›¾è¡¨å’Œæ•°æ®æ´å¯Ÿ
        
        å‚æ•°:
            data: æ•°æ®å†…å®¹ï¼ˆå¯ä»¥æ˜¯datasetã€csvDataæˆ–textDataï¼‰
            data_type: æ•°æ®ç±»å‹ï¼ˆdatasetã€csvã€textï¼‰
            user_prompt: ç”¨æˆ·æç¤º
            enable_insights: æ˜¯å¦å¯ç”¨æ•°æ®æ´å¯Ÿ
            use_llm: æ˜¯å¦ä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆå›¾è¡¨é…ç½®
            
        è¿”å›:
            åŒ…å«å›¾è¡¨è§„æ ¼å’Œæ´å¯Ÿçš„å­—å…¸
        """
        try:
            # 1. è§£ææ•°æ®
            df = self._parse_data(data, data_type)
            if df is None or df.empty:
                return {"error": "æ— æ³•è§£ææ•°æ®æˆ–æ•°æ®ä¸ºç©º"}
            
            # 2. æ ¹æ®use_llmå‚æ•°å†³å®šæ˜¯å¦ä½¿ç”¨å¤§æ¨¡å‹
            if use_llm and user_prompt and user_prompt.strip():
                logger.info("ä½¿ç”¨LLMæ¨¡å¼ç”Ÿæˆå›¾è¡¨é…ç½®")
                return await self._generate_chart_with_llm(df, user_prompt, enable_insights)
            elif use_llm:
                logger.info("å¯ç”¨LLMæ¨¡å¼ä½†æ— ç”¨æˆ·æç¤ºï¼Œä½¿ç”¨åŸºç¡€æç¤ºç”Ÿæˆå›¾è¡¨é…ç½®")
                default_prompt = "ç”Ÿæˆæœ€é€‚åˆè¿™ä¸ªæ•°æ®é›†çš„å›¾è¡¨ç±»å‹ï¼Œå¹¶æä¾›æ•°æ®æ´å¯Ÿåˆ†æ"
                return await self._generate_chart_with_llm(df, default_prompt, enable_insights)
            
            # 3. ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼ç”Ÿæˆå›¾è¡¨
            logger.info("ä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼ç”Ÿæˆå›¾è¡¨é…ç½®")
            return await self._generate_chart_traditional(df, enable_insights)
            
        except Exception as e:
            logger.exception(f"ç”Ÿæˆå›¾è¡¨æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return {"error": f"ç”Ÿæˆå›¾è¡¨å¤±è´¥: {str(e)}"}
    
    async def _generate_chart_traditional(self, df: pd.DataFrame, enable_insights: bool = True) -> Dict[str, Any]:
        """ä¼ ç»Ÿæ–¹å¼ç”Ÿæˆå›¾è¡¨"""
        
        # æ¨èå›¾è¡¨ç±»å‹
        chart_type = self._recommend_chart_type(df, None)
        
        # ç”ŸæˆEChartsé…ç½®
        chart_spec = self._generate_echarts_spec(df, chart_type)
        
        # åŸºäºå›¾è¡¨é…ç½®ç”Ÿæˆæ•°æ®æ´å¯Ÿ
        insights = []
        if enable_insights:
            insights = self._generate_insights_from_chart(chart_spec, chart_type, df)
        
        # ç”Ÿæˆæ´å¯Ÿæ–‡æ¡£
        insight_md = await self._generate_insight_markdown_from_chart(chart_spec, insights, chart_type, use_llm=False)
        
        return {
            "spec": chart_spec,
            "insight_md": insight_md,
            "insights": insights,
            "chart_type": chart_type
        }
    
    async def _generate_chart_with_llm(self, df: pd.DataFrame, user_prompt: str, enable_insights: bool = True) -> Dict[str, Any]:
        """ä½¿ç”¨LLMç”Ÿæˆå›¾è¡¨é…ç½®"""
        try:
            # è·å–LLMå®ä¾‹
            llm = get_llm_by_type("basic")
            
            # å‡†å¤‡æ•°æ®æ‘˜è¦
            data_summary = self._prepare_data_summary(df)
            
            # æ„å»ºLLMæç¤º
            prompt = self._build_llm_prompt(data_summary, user_prompt)
            
            # è°ƒç”¨LLM
            logger.info(f"å‘é€LLMè¯·æ±‚ï¼Œæç¤ºé•¿åº¦: {len(prompt)}")
            response = await llm.ainvoke(prompt)
            
            # è§£æLLMå“åº”
            chart_config = self._parse_llm_response(response.content)
            
            # åŸºäºLLMç”Ÿæˆçš„å›¾è¡¨é…ç½®ç”Ÿæˆæ´å¯Ÿ
            insights = []
            if enable_insights:
                chart_spec = chart_config.get("spec", {})
                chart_type = chart_config.get("chart_type", "unknown")
                insights = self._generate_insights_from_chart(chart_spec, chart_type, df)
            
            # ç”Ÿæˆæ´å¯Ÿæ–‡æ¡£
            chart_spec = chart_config.get("spec", {})
            chart_type = chart_config.get("chart_type", "unknown")
            insight_md = await self._generate_insight_markdown_from_chart(chart_spec, insights, chart_type, use_llm=True)
            
            return {
                "spec": chart_config.get("spec", {}),
                "insight_md": insight_md,
                "insights": insights,
                "chart_type": chart_config.get("chart_type", "unknown"),
                "llm_generated": True
            }
            
        except Exception as e:
            logger.error(f"LLMç”Ÿæˆå›¾è¡¨é…ç½®å¤±è´¥: {str(e)}")
            # å›é€€åˆ°ä¼ ç»Ÿæ¨¡å¼
            logger.info("å›é€€åˆ°ä¼ ç»Ÿæ¨¡å¼")
            return await self._generate_chart_traditional(df, enable_insights)
    
    def _parse_data(self, data: Any, data_type: str) -> Optional[pd.DataFrame]:
        """è§£æå„ç§æ ¼å¼çš„æ•°æ®ä¸ºDataFrame"""
        try:
            if data_type == "csv":
                if isinstance(data, str):
                    from io import StringIO
                    return pd.read_csv(StringIO(data))
                else:
                    return pd.DataFrame(data)
            elif data_type == "dataset":
                if isinstance(data, list) and data:
                    return pd.DataFrame(data)
                else:
                    return None
            elif data_type == "text":
                # å°è¯•ä»æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–æ•°æ®
                return self._extract_data_from_text(data)
            else:
                return None
        except Exception as e:
            logger.error(f"è§£ææ•°æ®å¤±è´¥: {str(e)}")
            return None
    
    def _extract_data_from_text(self, text: str) -> Optional[pd.DataFrame]:
        """ä»æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–æ•°æ®"""
        try:
            # å°è¯•è§£æä¸ºJSON
            if text.strip().startswith('[') or text.strip().startswith('{'):
                data = json.loads(text)
                if isinstance(data, list):
                    return pd.DataFrame(data)
            
            # å°è¯•æŒ‰è¡Œåˆ†å‰²å¹¶æŸ¥æ‰¾æ¨¡å¼
            lines = text.strip().split('\n')
            if len(lines) > 1:
                # ç®€å•çš„é”®å€¼å¯¹è§£æ
                data = []
                for line in lines:
                    if ':' in line:
                        parts = line.split(':', 1)
                        if len(parts) == 2:
                            key = parts[0].strip()
                            value = parts[1].strip()
                            try:
                                value = float(value)
                            except ValueError:
                                pass
                            data.append({"name": key, "value": value})
                
                if data:
                    return pd.DataFrame(data)
            
            return None
        except Exception:
            return None
    
    def _generate_insights(self, df: pd.DataFrame) -> List[Dict[str, Any]]:
        """ä½¿ç”¨DataInsightFrameworkç”Ÿæˆä¸“ä¸šæ•°æ®æ´å¯Ÿ"""
        insights = []
        
        try:
            # åˆ›å»ºæ•°æ®æ´å¯Ÿæ¡†æ¶å®ä¾‹
            framework = DataInsightFramework()
            
            # æ•°å€¼åˆ—åˆ†æ
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            
            for col in numeric_cols:
                try:
                    # ä½¿ç”¨æ¡†æ¶åˆ†ææ¯ä¸ªæ•°å€¼åˆ—
                    framework_results = framework.analyze(df, column=col)
                    
                    # è½¬æ¢æ¡†æ¶ç»“æœä¸ºå›¾è¡¨ç”Ÿæˆå™¨çš„æ ¼å¼
                    for result in framework_results:
                        insight = {
                            "type": result.insight_type,
                            "name": f"{col} - {result.algorithm}",
                            "description": result.description,
                            "data": clean_numpy_types({
                                "algorithm": result.algorithm,
                                "severity": result.severity,
                                "confidence": result.confidence,
                                "details": result.details,
                                "affected_data": result.affected_data,
                                "recommendations": result.recommendations
                            })
                        }
                        insights.append(insight)
                        
                except Exception as e:
                    logger.error(f"åˆ†æåˆ— {col} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
                    # å¦‚æœæ¡†æ¶åˆ†æå¤±è´¥ï¼Œæä¾›åŸºç¡€ç»Ÿè®¡ä½œä¸ºå¤‡é€‰
                    col_stats = clean_numpy_types({
                        "mean": float(df[col].mean()),
                        "median": float(df[col].median()),
                        "std": float(df[col].std()),
                        "min": float(df[col].min()),
                        "max": float(df[col].max())
                    })
                    insights.append({
                        "type": "basic_stats",
                        "name": f"{col} åŸºç¡€ç»Ÿè®¡",
                        "description": f"{col} çš„å¹³å‡å€¼ä¸º {col_stats['mean']:.2f}ï¼Œæ ‡å‡†å·®ä¸º {col_stats['std']:.2f}",
                        "data": col_stats
                    })
            
            # ç›¸å…³æ€§åˆ†æï¼ˆå¦‚æœæœ‰å¤šä¸ªæ•°å€¼åˆ—ï¼‰
            if len(numeric_cols) >= 2:
                try:
                    for i, col1 in enumerate(numeric_cols[:-1]):
                        for col2 in numeric_cols[i+1:]:
                            corr_results = framework.analyze_correlation_pair(df, col1, col2)
                            for result in corr_results:
                                insight = {
                                    "type": "correlation",
                                    "name": f"{col1} ä¸ {col2} ç›¸å…³æ€§åˆ†æ",
                                    "description": result.description,
                                    "data": clean_numpy_types({
                                        "algorithm": result.algorithm,
                                        "severity": result.severity,
                                        "confidence": result.confidence,
                                        "details": result.details,
                                        "recommendations": result.recommendations
                                    })
                                }
                                insights.append(insight)
                except Exception as e:
                    logger.error(f"ç›¸å…³æ€§åˆ†æå¤±è´¥: {str(e)}")
            
            # åˆ†ç±»åˆ—åˆ†æï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼Œå› ä¸ºæ¡†æ¶ä¸»è¦å¤„ç†æ•°å€¼æ•°æ®ï¼‰
            categorical_cols = df.select_dtypes(include=['object']).columns
            for col in categorical_cols:
                if df[col].nunique() <= 10:
                    try:
                        value_counts = df[col].value_counts()
                        insights.append({
                            "type": "categorical_analysis",
                            "name": f"{col} åˆ†å¸ƒåˆ†æ",
                            "description": f"{col} æœ‰ {len(value_counts)} ä¸ªä¸åŒå€¼ï¼Œæœ€å¸¸è§çš„æ˜¯ '{value_counts.index[0]}'",
                            "data": clean_numpy_types({
                                "unique_count": len(value_counts),
                                "top_values": value_counts.head(5).to_dict()
                            })
                        })
                    except Exception as e:
                        logger.error(f"åˆ†æåˆ†ç±»åˆ— {col} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            
            # ç¼ºå¤±å€¼åˆ†æ
            try:
                missing_data = df.isnull().sum()
                if missing_data.sum() > 0:
                    insights.append({
                        "type": "missing_data",
                        "name": "ç¼ºå¤±å€¼åˆ†æ",
                        "description": f"æ•°æ®ä¸­æœ‰ {missing_data.sum()} ä¸ªç¼ºå¤±å€¼",
                        "data": clean_numpy_types(missing_data[missing_data > 0].to_dict())
                    })
            except Exception as e:
                logger.error(f"ç¼ºå¤±å€¼åˆ†æå¤±è´¥: {str(e)}")
            
            # å¦‚æœæ²¡æœ‰ç”Ÿæˆä»»ä½•æ´å¯Ÿï¼Œæ·»åŠ åŸºæœ¬æ¦‚è§ˆ
            if not insights:
                insights.append({
                    "type": "basic_overview",
                    "name": "æ•°æ®æ¦‚è§ˆ", 
                    "description": f"æ•°æ®åŒ…å« {len(df)} è¡Œï¼Œ{len(df.columns)} åˆ—",
                    "data": {
                        "rows": len(df),
                        "columns": len(df.columns),
                        "column_names": df.columns.tolist()
                    }
                })
                
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ´å¯Ÿæ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {str(e)}")
            # å›é€€åˆ°åŸºæœ¬æ¦‚è§ˆ
            insights = [{
                "type": "error",
                "name": "åˆ†æå¤±è´¥",
                "description": f"æ•°æ®æ´å¯Ÿåˆ†æå¤±è´¥: {str(e)}ï¼Œä»…æä¾›åŸºæœ¬ä¿¡æ¯",
                "data": {
                    "rows": len(df),
                    "columns": len(df.columns),
                    "column_names": df.columns.tolist()
                }
            }]
        
        return insights
    
    def _recommend_chart_type(self, df: pd.DataFrame, user_prompt: Optional[str] = None) -> str:
        """æ¨èå›¾è¡¨ç±»å‹"""
        # åŸºäºç”¨æˆ·æç¤ºæ¨è
        if user_prompt:
            prompt_lower = user_prompt.lower()
            if any(word in prompt_lower for word in ['è¶‹åŠ¿', 'å˜åŒ–', 'æ—¶é—´', 'çº¿']):
                return 'line'
            elif any(word in prompt_lower for word in ['æ¯”è¾ƒ', 'å¯¹æ¯”', 'æŸ±']):
                return 'bar'
            elif any(word in prompt_lower for word in ['å æ¯”', 'æ¯”ä¾‹', 'é¥¼', 'åˆ†å¸ƒ']):
                return 'pie'
            elif any(word in prompt_lower for word in ['æ•£ç‚¹', 'ç›¸å…³', 'å…³ç³»']):
                return 'scatter'
        
        # åŸºäºæ•°æ®ç‰¹å¾æ¨è
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        categorical_cols = df.select_dtypes(include=['object']).columns
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ—¶é—´åºåˆ—æ•°æ®
        for col in numeric_cols:
            if self._is_date_column(df[col]):
                logger.info(f"æ£€æµ‹åˆ°æ—¶é—´åºåˆ—åˆ—: {col}")
                return 'line'  # æ—¶é—´åºåˆ—æ•°æ®æ¨èæŠ˜çº¿å›¾
        
        # æ£€æŸ¥åˆ—åæ˜¯å¦åŒ…å«æ—¶é—´ç›¸å…³å…³é”®è¯
        for col in df.columns:
            col_lower = col.lower()
            if any(keyword in col_lower for keyword in ['æ—¥æœŸ', 'æ—¶é—´', 'å¹´', 'æœˆ', 'æ—¥', 'date', 'time', 'èˆªç­æ—¥']):
                logger.info(f"æ ¹æ®åˆ—åæ£€æµ‹åˆ°æ—¶é—´ç›¸å…³æ•°æ®: {col}")
                return 'line'
        
        if len(numeric_cols) >= 2 and len(categorical_cols) == 0:
            return 'scatter'  # ä¸¤ä¸ªæ•°å€¼åˆ—ï¼Œæ¨èæ•£ç‚¹å›¾
        elif len(numeric_cols) == 1 and len(categorical_cols) == 1:
            if df[categorical_cols[0]].nunique() <= 10:
                return 'bar'  # åˆ†ç±»+æ•°å€¼ï¼Œæ¨èæŸ±çŠ¶å›¾
            else:
                return 'line'  # åˆ†ç±»è¿‡å¤šï¼Œæ¨èæŠ˜çº¿å›¾
        elif len(categorical_cols) >= 1 and len(numeric_cols) >= 1:
            unique_count = df[categorical_cols[0]].nunique()
            if unique_count <= 8:
                return 'pie'  # åˆ†ç±»ä¸å¤šï¼Œæ¨èé¥¼å›¾
            else:
                return 'bar'  # åˆ†ç±»è¾ƒå¤šï¼Œæ¨èæŸ±çŠ¶å›¾
        
        return 'bar'  # é»˜è®¤æŸ±çŠ¶å›¾
    
    def _is_date_column(self, series: pd.Series) -> bool:
        """æ£€æŸ¥æ•°æ®åˆ—æ˜¯å¦ä¸ºæ—¥æœŸæ ¼å¼"""
        try:
            # æ£€æŸ¥æ˜¯å¦ä¸ºYYYYMMDDæ ¼å¼çš„æ•´æ•°
            if series.dtype in ['int64', 'int32']:
                sample_values = series.dropna().head(5)
                for val in sample_values:
                    if 19000000 <= val <= 21000000:  # å¤§è‡´çš„æ—¥æœŸèŒƒå›´
                        date_str = str(val)
                        if len(date_str) == 8:
                            year = int(date_str[:4])
                            month = int(date_str[4:6])
                            day = int(date_str[6:8])
                            if 1900 <= year <= 2100 and 1 <= month <= 12 and 1 <= day <= 31:
                                return True
            return False
        except:
            return False
    
    def _prepare_data_summary(self, df: pd.DataFrame) -> Dict[str, Any]:
        """å‡†å¤‡æ•°æ®æ‘˜è¦ç”¨äºLLM"""
        try:
            summary = {
                "shape": df.shape,
                "columns": df.columns.tolist(),
                "dtypes": {col: str(dtype) for col, dtype in df.dtypes.items()},
                "sample_data": df.head(5).to_dict('records'),
                "numeric_columns": df.select_dtypes(include=[np.number]).columns.tolist(),
                "categorical_columns": df.select_dtypes(include=['object']).columns.tolist(),
                "null_counts": df.isnull().sum().to_dict()
            }
            
            # æ·»åŠ æ•°å€¼åˆ—çš„ç»Ÿè®¡ä¿¡æ¯
            numeric_stats = {}
            for col in summary["numeric_columns"]:
                try:
                    numeric_stats[col] = {
                        "min": float(df[col].min()),
                        "max": float(df[col].max()),
                        "mean": float(df[col].mean()),
                        "std": float(df[col].std())
                    }
                except:
                    numeric_stats[col] = {"error": "ç»Ÿè®¡è®¡ç®—å¤±è´¥"}
            summary["numeric_stats"] = numeric_stats
            
            return summary
        except Exception as e:
            logger.error(f"å‡†å¤‡æ•°æ®æ‘˜è¦å¤±è´¥: {str(e)}")
            return {"error": str(e)}
    
    def _build_llm_prompt(self, data_summary: Dict[str, Any], user_prompt: str) -> str:
        """æ„å»ºLLMæç¤º"""
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®å¯è§†åŒ–ä¸“å®¶ã€‚è¯·æ ¹æ®ä»¥ä¸‹æ•°æ®ç‰¹å¾å’Œç”¨æˆ·éœ€æ±‚ï¼Œç”Ÿæˆæœ€åˆé€‚çš„EChartsé…ç½®ã€‚

æ•°æ®æ¦‚å†µ:
- æ•°æ®è¡Œæ•°: {data_summary.get('shape', [0, 0])[0]}
- æ•°æ®åˆ—æ•°: {data_summary.get('shape', [0, 0])[1]}
- åˆ—å: {data_summary.get('columns', [])}
- æ•°å€¼åˆ—: {data_summary.get('numeric_columns', [])}
- åˆ†ç±»åˆ—: {data_summary.get('categorical_columns', [])}

æ•°æ®æ ·æœ¬:
{json.dumps(data_summary.get('sample_data', []), ensure_ascii=False, indent=2)}

æ•°å€¼åˆ—ç»Ÿè®¡:
{json.dumps(data_summary.get('numeric_stats', {}), ensure_ascii=False, indent=2)}

ç”¨æˆ·éœ€æ±‚: {user_prompt}

è¯·ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„EChartsé…ç½®å¯¹è±¡ï¼Œè¦æ±‚:
1. æ ¹æ®æ•°æ®ç‰¹å¾é€‰æ‹©æœ€åˆé€‚çš„å›¾è¡¨ç±»å‹ï¼ˆæŸ±çŠ¶å›¾ã€æŠ˜çº¿å›¾ã€é¥¼å›¾ã€æ•£ç‚¹å›¾ç­‰ï¼‰
2. é…ç½®å¿…é¡»æ˜¯æœ‰æ•ˆçš„ECharts optionå¯¹è±¡
3. åŒ…å«åˆé€‚çš„æ ‡é¢˜ã€å›¾ä¾‹ã€åæ ‡è½´æ ‡ç­¾
4. é¢œè‰²æ­é…è¦ç¾è§‚
5. å¦‚æœæ˜¯æ—¶é—´åºåˆ—æ•°æ®ï¼Œè¦æ­£ç¡®å¤„ç†æ—¶é—´è½´
6. å“åº”å¼è®¾è®¡ï¼Œé€‚åº”ä¸åŒå±å¹•å°ºå¯¸

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›:
{{
    "chart_type": "å›¾è¡¨ç±»å‹ï¼ˆå¦‚barã€lineã€pieã€scatterç­‰ï¼‰",
    "spec": {{
        "title": {{"text": "å›¾è¡¨æ ‡é¢˜"}},
        "tooltip": {{}},
        "legend": {{}},
        "xAxis": {{}},
        "yAxis": {{}},
        "series": [{{}}]
    }}
}}

æ³¨æ„ï¼š
- åªè¿”å›JSONæ ¼å¼çš„é…ç½®ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—è¯´æ˜
- ç¡®ä¿æ‰€æœ‰æ•°æ®å¼•ç”¨éƒ½ä½¿ç”¨å®é™…çš„åˆ—å
- å¦‚æœæ£€æµ‹åˆ°æ—¶é—´æ ¼å¼æ•°æ®ï¼ˆå¦‚YYYYMMDDï¼‰ï¼Œè¦è¿›è¡Œé€‚å½“çš„æ ¼å¼è½¬æ¢
"""
        return prompt
    
    def _parse_llm_response(self, response_content: str) -> Dict[str, Any]:
        """è§£æLLMå“åº”"""
        try:
            # æ¸…ç†å“åº”å†…å®¹ï¼Œç§»é™¤å¯èƒ½çš„markdownæ ‡è®°
            content = response_content.strip()
            if content.startswith('```json'):
                content = content[7:]
            if content.startswith('```'):
                content = content[3:]
            if content.endswith('```'):
                content = content[:-3]
            
            # è§£æJSON
            chart_config = json.loads(content.strip())
            
            # éªŒè¯å¿…éœ€çš„å­—æ®µ
            if not isinstance(chart_config, dict):
                raise ValueError("å“åº”ä¸æ˜¯æœ‰æ•ˆçš„å­—å…¸æ ¼å¼")
            
            if "spec" not in chart_config:
                raise ValueError("å“åº”ä¸­ç¼ºå°‘specå­—æ®µ")
            
            return chart_config
            
        except json.JSONDecodeError as e:
            logger.error(f"è§£æLLMå“åº”JSONå¤±è´¥: {str(e)}")
            logger.error(f"åŸå§‹å“åº”: {response_content}")
            raise ValueError(f"LLMå“åº”ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼: {str(e)}")
        except Exception as e:
            logger.error(f"è§£æLLMå“åº”å¤±è´¥: {str(e)}")
            raise ValueError(f"è§£æLLMå“åº”å¤±è´¥: {str(e)}")
    
    def _generate_echarts_spec(self, df: pd.DataFrame, chart_type: str) -> Dict[str, Any]:
        """ç”ŸæˆEChartsé…ç½®"""
        try:
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            categorical_cols = df.select_dtypes(include=['object']).columns
            
            # åŸºç¡€é…ç½®
            base_config = {
                "title": {"text": "æ•°æ®å¯è§†åŒ–å›¾è¡¨", "left": "center"},
                "tooltip": {"trigger": "axis" if chart_type in ['line', 'bar'] else "item"},
                "legend": {"orient": "horizontal", "left": "center", "top": "bottom"},
                "toolbox": {
                    "show": True,
                    "feature": {
                        "dataView": {"show": True, "readOnly": False},
                        "magicType": {"show": True, "type": ["line", "bar"]},
                        "restore": {"show": True},
                        "saveAsImage": {"show": True}
                    }
                }
            }
            
            if chart_type == 'bar':
                return self._generate_bar_chart(df, base_config, numeric_cols, categorical_cols)
            elif chart_type == 'line':
                return self._generate_line_chart(df, base_config, numeric_cols, categorical_cols)
            elif chart_type == 'pie':
                return self._generate_pie_chart(df, base_config, numeric_cols, categorical_cols)
            elif chart_type == 'scatter':
                return self._generate_scatter_chart(df, base_config, numeric_cols)
            else:
                return self._generate_bar_chart(df, base_config, numeric_cols, categorical_cols)
                
        except Exception as e:
            logger.error(f"ç”ŸæˆEChartsé…ç½®å¤±è´¥: {str(e)}")
            return {"error": f"ç”Ÿæˆå›¾è¡¨é…ç½®å¤±è´¥: {str(e)}"}
    
    def _generate_bar_chart(self, df: pd.DataFrame, base_config: Dict, numeric_cols, categorical_cols) -> Dict:
        """ç”ŸæˆæŸ±çŠ¶å›¾é…ç½®"""
        config = base_config.copy()
        
        if len(categorical_cols) > 0 and len(numeric_cols) > 0:
            category_col = categorical_cols[0]
            value_col = numeric_cols[0]
            
            categories = df[category_col].astype(str).tolist()
            values = df[value_col].tolist()
            
            config.update({
                "xAxis": {"type": "category", "data": categories},
                "yAxis": {"type": "value"},
                "series": [{
                    "name": value_col,
                    "type": "bar",
                    "data": values,
                    "itemStyle": {"color": "#5470c6"}
                }]
            })
        else:
            # å¦‚æœæ²¡æœ‰åˆé€‚çš„åˆ†ç±»åˆ—ï¼Œä½¿ç”¨è¡Œç´¢å¼•
            if len(numeric_cols) > 0:
                value_col = numeric_cols[0]
                config.update({
                    "xAxis": {"type": "category", "data": [f"é¡¹ç›®{i+1}" for i in range(len(df))]},
                    "yAxis": {"type": "value"},
                    "series": [{
                        "name": value_col,
                        "type": "bar",
                        "data": df[value_col].tolist(),
                        "itemStyle": {"color": "#5470c6"}
                    }]
                })
        
        return config
    
    def _generate_line_chart(self, df: pd.DataFrame, base_config: Dict, numeric_cols, categorical_cols) -> Dict:
        """ç”ŸæˆæŠ˜çº¿å›¾é…ç½®"""
        config = base_config.copy()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ—¶é—´åˆ—
        time_col = None
        value_col = None
        
        # ä¼˜å…ˆæŸ¥æ‰¾æ—¶é—´åˆ—
        for col in numeric_cols:
            if self._is_date_column(df[col]):
                time_col = col
                break
        
        # å¦‚æœæ²¡æ‰¾åˆ°æ•°å€¼æ—¶é—´åˆ—ï¼Œæ£€æŸ¥åˆ—å
        if not time_col:
            for col in df.columns:
                col_lower = col.lower()
                if any(keyword in col_lower for keyword in ['æ—¥æœŸ', 'æ—¶é—´', 'å¹´', 'æœˆ', 'æ—¥', 'date', 'time', 'èˆªç­æ—¥']):
                    time_col = col
                    break
        
        # æ‰¾åˆ°å€¼åˆ—ï¼ˆéæ—¶é—´åˆ—çš„æ•°å€¼åˆ—ï¼‰
        for col in numeric_cols:
            if col != time_col:
                value_col = col
                break
        
        if time_col and value_col:
            # å¤„ç†æ—¶é—´åºåˆ—æ•°æ®
            if self._is_date_column(df[time_col]):
                # è½¬æ¢YYYYMMDDæ ¼å¼åˆ°å¯è¯»æ—¥æœŸ
                categories = []
                for val in df[time_col]:
                    date_str = str(val)
                    if len(date_str) == 8:
                        year = date_str[:4]
                        month = date_str[4:6]
                        day = date_str[6:8]
                        categories.append(f"{year}-{month}-{day}")
                    else:
                        categories.append(str(val))
            else:
                categories = df[time_col].astype(str).tolist()
            
            values = df[value_col].tolist()
            
            config.update({
                "xAxis": {
                    "type": "category", 
                    "data": categories,
                    "name": time_col,
                    "axisLabel": {
                        "rotate": 45,
                        "fontSize": 10
                    }
                },
                "yAxis": {
                    "type": "value",
                    "name": value_col
                },
                "series": [{
                    "name": value_col,
                    "type": "line",
                    "data": values,
                    "smooth": True,
                    "lineStyle": {"color": "#5470c6", "width": 2},
                    "symbol": "circle",
                    "symbolSize": 6
                }],
                "grid": {
                    "left": "10%",
                    "right": "10%",
                    "bottom": "20%",
                    "top": "15%",
                    "containLabel": True
                },
                "dataZoom": [
                    {
                        "type": "slider",
                        "show": True,
                        "xAxisIndex": [0],
                        "start": 0,
                        "end": 100
                    },
                    {
                        "type": "inside",
                        "xAxisIndex": [0],
                        "start": 0,
                        "end": 100
                    }
                ]
            })
        elif len(categorical_cols) > 0 and len(numeric_cols) > 0:
            category_col = categorical_cols[0]
            value_col = numeric_cols[0]
            
            categories = df[category_col].astype(str).tolist()
            values = df[value_col].tolist()
            
            config.update({
                "xAxis": {"type": "category", "data": categories},
                "yAxis": {"type": "value"},
                "series": [{
                    "name": value_col,
                    "type": "line",
                    "data": values,
                    "smooth": True,
                    "lineStyle": {"color": "#5470c6"}
                }]
            })
        else:
            if len(numeric_cols) > 0:
                value_col = numeric_cols[0]
                config.update({
                    "xAxis": {"type": "category", "data": [f"ç‚¹{i+1}" for i in range(len(df))]},
                    "yAxis": {"type": "value"},
                    "series": [{
                        "name": value_col,
                        "type": "line",
                        "data": df[value_col].tolist(),
                        "smooth": True,
                        "lineStyle": {"color": "#5470c6"}
                    }]
                })
        
        return config
    
    def _generate_pie_chart(self, df: pd.DataFrame, base_config: Dict, numeric_cols, categorical_cols) -> Dict:
        """ç”Ÿæˆé¥¼å›¾é…ç½®"""
        config = base_config.copy()
        
        if len(categorical_cols) > 0 and len(numeric_cols) > 0:
            category_col = categorical_cols[0]
            value_col = numeric_cols[0]
            
            # èšåˆç›¸åŒåˆ†ç±»çš„æ•°æ®
            grouped = df.groupby(category_col)[value_col].sum().reset_index()
            
            data = [
                {"name": str(row[category_col]), "value": float(row[value_col])}
                for _, row in grouped.iterrows()
            ]
            
            config.update({
                "series": [{
                    "name": "æ•°æ®",
                    "type": "pie",
                    "radius": "50%",
                    "data": data,
                    "emphasis": {
                        "itemStyle": {
                            "shadowBlur": 10,
                            "shadowOffsetX": 0,
                            "shadowColor": "rgba(0, 0, 0, 0.5)"
                        }
                    }
                }]
            })
        else:
            # å¦‚æœåªæœ‰ä¸€åˆ—æ•°æ®ï¼ŒæŒ‰å€¼åˆ†å¸ƒ
            if len(numeric_cols) > 0:
                value_col = numeric_cols[0]
                data = [
                    {"name": f"é¡¹ç›®{i+1}", "value": float(val)}
                    for i, val in enumerate(df[value_col].tolist())
                ]
                
                config.update({
                    "series": [{
                        "name": "æ•°æ®",
                        "type": "pie",
                        "radius": "50%",
                        "data": data
                    }]
                })
        
        return config
    
    def _generate_scatter_chart(self, df: pd.DataFrame, base_config: Dict, numeric_cols) -> Dict:
        """ç”Ÿæˆæ•£ç‚¹å›¾é…ç½®"""
        config = base_config.copy()
        
        if len(numeric_cols) >= 2:
            x_col = numeric_cols[0]
            y_col = numeric_cols[1]
            
            data = [[float(row[x_col]), float(row[y_col])] for _, row in df.iterrows()]
            
            config.update({
                "xAxis": {"type": "value", "name": x_col},
                "yAxis": {"type": "value", "name": y_col},
                "series": [{
                    "name": "æ•°æ®ç‚¹",
                    "type": "scatter",
                    "data": data,
                    "symbolSize": 8,
                    "itemStyle": {"color": "#5470c6"}
                }]
            })
        
        return config
    
    def _generate_insight_markdown(self, df: pd.DataFrame, insights: List[Dict], chart_type: str) -> str:
        """ç”Ÿæˆæ´å¯Ÿæ–‡æ¡£ï¼ˆMarkdownæ ¼å¼ï¼‰"""
        md_content = []
        
        md_content.append("# æ•°æ®åˆ†ææŠ¥å‘Š")
        md_content.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        md_content.append(f"**å›¾è¡¨ç±»å‹**: {chart_type}")
        md_content.append("")
        
        md_content.append("## æ•°æ®æ¦‚è§ˆ")
        md_content.append(f"- æ•°æ®è¡Œæ•°: {len(df)}")
        md_content.append(f"- æ•°æ®åˆ—æ•°: {len(df.columns)}")
        md_content.append(f"- åˆ—å: {', '.join(df.columns.tolist())}")
        md_content.append("")
        
        if insights:
            # åˆ†ç±»æ˜¾ç¤ºæ´å¯Ÿ
            severity_order = {'critical': 'ğŸ”´ å…³é”®é—®é¢˜', 'high': 'ğŸŸ  é‡è¦å‘ç°', 'medium': 'ğŸŸ¡ ä¸€èˆ¬å‘ç°', 'low': 'ğŸŸ¢ åŸºç¡€ä¿¡æ¯'}
            
            # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç»„
            insights_by_severity = {}
            basic_insights = []
            
            for insight in insights:
                insight_data = insight.get('data', {})
                severity = insight_data.get('severity', 'unknown')
                
                # ç‰¹æ®Šå¤„ç†éæ¡†æ¶ç”Ÿæˆçš„æ´å¯Ÿ
                if insight['type'] in ['categorical_analysis', 'missing_data', 'basic_overview', 'error']:
                    basic_insights.append(insight)
                else:
                    if severity not in insights_by_severity:
                        insights_by_severity[severity] = []
                    insights_by_severity[severity].append(insight)
            
            # æ˜¾ç¤ºæ¡†æ¶åˆ†æç»“æœ
            md_content.append("## ä¸“ä¸šæ•°æ®æ´å¯Ÿ")
            if insights_by_severity:
                for severity in ['critical', 'high', 'medium', 'low']:
                    if severity in insights_by_severity:
                        md_content.append(f"### {severity_order[severity]}")
                        for insight in insights_by_severity[severity]:
                            md_content.append(f"#### {insight['name']}")
                            md_content.append(insight['description'])
                            
                            insight_data = insight.get('data', {})
                            confidence = insight_data.get('confidence', 0)
                            algorithm = insight_data.get('algorithm', 'æœªçŸ¥')
                            
                            md_content.append(f"- **ç®—æ³•**: {algorithm}")
                            md_content.append(f"- **ç½®ä¿¡åº¦**: {confidence:.2f}")
                            
                            # æ˜¾ç¤ºå»ºè®®
                            recommendations = insight_data.get('recommendations', [])
                            if recommendations:
                                md_content.append("- **å»ºè®®**:")
                                for rec in recommendations[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ªå»ºè®®
                                    md_content.append(f"  - {rec}")
                            
                            # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯ï¼ˆå¦‚æœæœ‰å¼‚å¸¸æ•°æ®ï¼‰
                            affected_data = insight_data.get('affected_data', [])
                            if affected_data and len(affected_data) <= 10:  # åªæ˜¾ç¤ºå°‘é‡å¼‚å¸¸æ•°æ®
                                md_content.append(f"- **å—å½±å“æ•°æ®ä½ç½®**: {affected_data}")
                            elif len(affected_data) > 10:
                                md_content.append(f"- **å—å½±å“æ•°æ®**: {len(affected_data)} ä¸ªæ•°æ®ç‚¹")
                            
                            md_content.append("")
            
            # æ˜¾ç¤ºåŸºç¡€åˆ†æç»“æœ
            if basic_insights:
                md_content.append("### ğŸ“Š åŸºç¡€æ•°æ®åˆ†æ")
                for insight in basic_insights:
                    md_content.append(f"#### {insight['name']}")
                    md_content.append(insight['description'])
                    
                    # æ˜¾ç¤ºåˆ†ç±»åˆ†æçš„è¯¦ç»†ä¿¡æ¯
                    if insight['type'] == 'categorical_analysis':
                        top_values = insight.get('data', {}).get('top_values', {})
                        if top_values:
                            md_content.append("- **åˆ†å¸ƒè¯¦æƒ…**:")
                            for value, count in list(top_values.items())[:5]:
                                md_content.append(f"  - {value}: {count}")
                    
                    # æ˜¾ç¤ºç¼ºå¤±å€¼è¯¦æƒ…
                    elif insight['type'] == 'missing_data':
                        missing_details = insight.get('data', {})
                        if missing_details:
                            md_content.append("- **ç¼ºå¤±å€¼è¯¦æƒ…**:")
                            for col, count in missing_details.items():
                                md_content.append(f"  - {col}: {count} ä¸ªç¼ºå¤±å€¼")
                    
                    md_content.append("")
        
        md_content.append("## å›¾è¡¨è¯´æ˜")
        chart_descriptions = {
            'bar': "æŸ±çŠ¶å›¾é€‚åˆæ¯”è¾ƒä¸åŒç±»åˆ«çš„æ•°å€¼å¤§å°",
            'line': "æŠ˜çº¿å›¾é€‚åˆå±•ç¤ºæ•°æ®éšæ—¶é—´æˆ–å…¶ä»–è¿ç»­å˜é‡çš„å˜åŒ–è¶‹åŠ¿",
            'pie': "é¥¼å›¾é€‚åˆå±•ç¤ºå„éƒ¨åˆ†å æ•´ä½“çš„æ¯”ä¾‹å…³ç³»",
            'scatter': "æ•£ç‚¹å›¾é€‚åˆæ¢ç´¢ä¸¤ä¸ªæ•°å€¼å˜é‡ä¹‹é—´çš„ç›¸å…³å…³ç³»"
        }
        md_content.append(chart_descriptions.get(chart_type, "å›¾è¡¨å±•ç¤ºäº†æ•°æ®çš„å¯è§†åŒ–ç»“æœ"))
        
        # æ·»åŠ åˆ†æè¯´æ˜
        md_content.append("")
        md_content.append("## åˆ†æè¯´æ˜")
        md_content.append("æœ¬æŠ¥å‘Šä½¿ç”¨äº†ä¸“ä¸šçš„æ•°æ®æ´å¯Ÿæ¡†æ¶è¿›è¡Œåˆ†æï¼ŒåŒ…æ‹¬ï¼š")
        md_content.append("- **å¼‚å¸¸æ£€æµ‹**: Z-Scoreã€IQRã€LOFç­‰ç®—æ³•è¯†åˆ«æ•°æ®å¼‚å¸¸")
        md_content.append("- **è¶‹åŠ¿åˆ†æ**: Mann-Kendallæ£€éªŒè¯†åˆ«æ•°æ®è¶‹åŠ¿")
        md_content.append("- **å˜åŒ–ç‚¹æ£€æµ‹**: Page-Hinkleyå’Œè´å¶æ–¯æ–¹æ³•è¯†åˆ«æ•°æ®è½¬æŠ˜ç‚¹")
        md_content.append("- **ç›¸å…³æ€§åˆ†æ**: Pearsonå’ŒSpearmanç›¸å…³ç³»æ•°åˆ†æå˜é‡å…³ç³»")
        md_content.append("- **èšç±»åˆ†æ**: DBSCANç®—æ³•è¯†åˆ«æ•°æ®ç¾¤ç»„å’Œå¼‚å¸¸ç‚¹")
        
        return "\n".join(md_content) 
    
    async def _optimize_markdown_with_llm(self, original_md: str, chart_spec: Dict[str, Any], insights: List[Dict], chart_type: str) -> str:
        """ä½¿ç”¨LLMä¼˜åŒ–markdownå†…å®¹"""
        try:
            # è·å–LLMå®ä¾‹
            llm = get_llm_by_type("basic")
            
            # å‡†å¤‡æ•°æ®æ‘˜è¦
            chart_summary = self._prepare_chart_summary(chart_spec, insights, chart_type)
            
            # æ„å»ºä¼˜åŒ–æç¤º
            prompt = self._build_markdown_optimization_prompt(original_md, chart_summary)
            
            # è°ƒç”¨LLM
            logger.info("ä½¿ç”¨LLMä¼˜åŒ–Markdownå†…å®¹")
            response = await llm.ainvoke(prompt)
            
            # è§£æå¹¶éªŒè¯LLMå“åº”
            optimized_md = self._parse_markdown_response(response.content)
            
            return optimized_md
            
        except Exception as e:
            logger.error(f"LLMä¼˜åŒ–Markdownå¤±è´¥: {str(e)}")
            raise e
    
    def _prepare_chart_summary(self, chart_spec: Dict[str, Any], insights: List[Dict], chart_type: str) -> Dict[str, Any]:
        """å‡†å¤‡å›¾è¡¨æ‘˜è¦ç”¨äºLLMä¼˜åŒ–"""
        try:
            summary = {
                "chart_type": chart_type,
                "series_count": len(chart_spec.get("series", [])),
                "insights_count": len(insights),
                "critical_insights": [],
                "high_insights": [],
                "chart_insights": []
            }
            
            # æå–å…³é”®æ´å¯Ÿ
            for insight in insights:
                # ç¡®ä¿ insight æ˜¯å­—å…¸ç±»å‹
                if not isinstance(insight, dict):
                    logger.warning(f"è·³è¿‡éå­—å…¸ç±»å‹çš„æ´å¯Ÿ: {type(insight)}")
                    continue
                
                insight_data = insight.get('data', {})
                # ç¡®ä¿ insight_data æ˜¯å­—å…¸ç±»å‹
                if not isinstance(insight_data, dict):
                    insight_data = {}
                
                severity = insight_data.get('severity', 'low')
                data_source = insight_data.get('data_source', 'unknown')
                
                insight_summary = {
                    "name": insight.get('name', 'æœªçŸ¥'),
                    "description": insight.get('description', ''),
                    "type": insight.get('type', 'unknown')
                }
                
                if severity == 'critical':
                    summary["critical_insights"].append(insight_summary)
                elif severity == 'high':
                    summary["high_insights"].append(insight_summary)
                elif data_source == 'chart_data':
                    summary["chart_insights"].append(insight_summary)
            
            # æå–å›¾è¡¨æ•°æ®ä¿¡æ¯
            if chart_spec.get("series") and len(chart_spec["series"]) > 0:
                first_series = chart_spec["series"][0]
                
                # ç¡®ä¿ first_series æ˜¯å­—å…¸ç±»å‹
                if isinstance(first_series, dict):
                    summary["data_count"] = len(first_series.get("data", []))
                    summary["series_name"] = first_series.get("name", "æœªå‘½å")
                else:
                    # å¦‚æœä¸æ˜¯å­—å…¸ï¼Œè®¾ç½®é»˜è®¤å€¼
                    summary["data_count"] = 0
                    summary["series_name"] = "æœªå‘½å"
                
                # æå–Xè½´å’ŒYè½´ä¿¡æ¯
                logger.info(f"chart_spec: {chart_spec}")
                if "xAxis" in chart_spec and isinstance(chart_spec["xAxis"], dict):
                    summary["x_axis_name"] = chart_spec["xAxis"].get("name", "")
                if "yAxis" in chart_spec and isinstance(chart_spec["yAxis"], dict):
                    summary["y_axis_name"] = chart_spec["yAxis"].get("name", "")
            
            return summary
            
        except Exception as e:
            logger.error(f"å‡†å¤‡å›¾è¡¨æ‘˜è¦å¤±è´¥: {str(e)}")
            return {"error": str(e)}
    
    def _build_markdown_optimization_prompt(self, original_md: str, chart_summary: Dict[str, Any]) -> str:
        """æ„å»ºMarkdownä¼˜åŒ–æç¤º"""
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†æå¸ˆå’ŒæŠ€æœ¯å†™ä½œä¸“å®¶ã€‚è¯·ä¼˜åŒ–ä»¥ä¸‹æ•°æ®åˆ†ææŠ¥å‘Šçš„Markdownå†…å®¹ï¼Œä½¿å…¶æ›´åŠ ä¸“ä¸šã€æ˜“è¯»å’Œå¯Œæœ‰æ´å¯ŸåŠ›ã€‚

åŸå§‹æŠ¥å‘Šå†…å®¹:
{original_md}

å›¾è¡¨æ‘˜è¦ä¿¡æ¯:
- å›¾è¡¨ç±»å‹: {chart_summary.get('chart_type', 'æœªçŸ¥')}
- æ•°æ®ç³»åˆ—æ•°: {chart_summary.get('series_count', 0)}
- æ•°æ®ç‚¹æ•°é‡: {chart_summary.get('data_count', 0)}
- æ´å¯Ÿæ€»æ•°: {chart_summary.get('insights_count', 0)}
- å…³é”®å‘ç°æ•°: {len(chart_summary.get('critical_insights', []))}
- é‡è¦å‘ç°æ•°: {len(chart_summary.get('high_insights', []))}

å…³é”®æ´å¯Ÿä¿¡æ¯:
{json.dumps(chart_summary.get('critical_insights', []) + chart_summary.get('high_insights', []), ensure_ascii=False, indent=2)}

ä¼˜åŒ–è¦æ±‚:
1. **ä¿æŒç»“æ„**: ä¿æŒåŸæœ‰çš„Markdownç« èŠ‚ç»“æ„ï¼Œä¸è¦åˆ é™¤æˆ–é‡ç»„ä¸»è¦ç« èŠ‚
2. **ä¼˜åŒ–è¯­è¨€**: ä½¿ç”¨æ›´ä¸“ä¸šã€å‡†ç¡®çš„æ•°æ®åˆ†ææœ¯è¯­
3. **å¢å¼ºå¯è¯»æ€§**: æ”¹è¿›è¡¨è¾¾æ–¹å¼ï¼Œä½¿å†…å®¹æ›´æµç•…æ˜“æ‡‚
4. **çªå‡ºé‡ç‚¹**: å¼ºè°ƒå…³é”®å‘ç°å’Œé‡è¦æ´å¯Ÿ
5. **æ·»åŠ æ€»ç»“**: åœ¨æ¯ä¸ªä¸»è¦ç« èŠ‚åæ·»åŠ ç®€è¦æ€»ç»“
6. **ä¿æŒæ•°æ®**: ä¿ç•™æ‰€æœ‰å…·ä½“çš„æ•°æ®ã€æ•°å­—å’Œç®—æ³•åç§°
7. **æ”¹è¿›æ ¼å¼**: ä¼˜åŒ–è¡¨æ ¼ã€åˆ—è¡¨å’Œå¼ºè°ƒæ ‡è®°çš„ä½¿ç”¨
8. **ä¸“ä¸šæœ¯è¯­**: ä½¿ç”¨å‡†ç¡®çš„ç»Ÿè®¡å­¦å’Œæ•°æ®åˆ†æä¸“ä¸šæœ¯è¯­
9. **é€»è¾‘è¿è´¯**: ç¡®ä¿å„éƒ¨åˆ†å†…å®¹é€»è¾‘è¿è´¯ï¼Œè¿‡æ¸¡è‡ªç„¶

è¯·è¿”å›ä¼˜åŒ–åçš„å®Œæ•´Markdownå†…å®¹ï¼Œç¡®ä¿å†…å®¹ä¸“ä¸šã€å‡†ç¡®ä¸”æ˜“äºç†è§£ã€‚ä¸è¦æ·»åŠ åŸæ–‡ä¸­æ²¡æœ‰çš„ä¿¡æ¯ï¼Œä½†å¯ä»¥æ”¹è¿›è¡¨è¾¾æ–¹å¼å’Œç»„ç»‡ç»“æ„ã€‚"""

        return prompt
    
    def _parse_markdown_response(self, response_content: str) -> str:
        """è§£æLLMè¿”å›çš„Markdownå†…å®¹"""
        try:
            # æ¸…ç†å“åº”å†…å®¹
            content = response_content.strip()
            
            # ç§»é™¤å¯èƒ½çš„markdownä»£ç å—æ ‡è®°
            if content.startswith('```markdown'):
                content = content[11:]
            elif content.startswith('```'):
                content = content[3:]
            if content.endswith('```'):
                content = content[:-3]
            
            # éªŒè¯å†…å®¹æ˜¯å¦åŒ…å«åŸºæœ¬çš„Markdownç»“æ„
            content = content.strip()
            if not content or len(content) < 100:
                raise ValueError("LLMè¿”å›çš„å†…å®¹è¿‡çŸ­ï¼Œå¯èƒ½ä¸å®Œæ•´")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å¿…è¦çš„ç« èŠ‚æ ‡é¢˜
            required_sections = ["å›¾è¡¨æ•°æ®åˆ†ææŠ¥å‘Š", "å›¾è¡¨æ¦‚è§ˆ"]
            for section in required_sections:
                if section not in content:
                    logger.warning(f"ä¼˜åŒ–åçš„å†…å®¹ç¼ºå°‘å¿…è¦ç« èŠ‚: {section}")
            
            return content
            
        except Exception as e:
            logger.error(f"è§£æLLM Markdownå“åº”å¤±è´¥: {str(e)}")
            raise ValueError(f"è§£æLLMå“åº”å¤±è´¥: {str(e)}")

    def _extract_data_from_chart_spec(self, chart_spec: Dict[str, Any], chart_type: str) -> Optional[pd.DataFrame]:
        """ä»å›¾è¡¨é…ç½®ä¸­æå–å®é™…ä½¿ç”¨çš„æ•°æ®"""
        logger.info(f"chart_spec: {chart_spec}")
        try:
            if "series" not in chart_spec or not chart_spec["series"]:
                return None
            
            series_data = chart_spec["series"][0]  # å–ç¬¬ä¸€ä¸ªç³»åˆ—çš„æ•°æ®
            
            if chart_type in ['bar', 'line']:
                # æŸ±çŠ¶å›¾å’ŒæŠ˜çº¿å›¾
                x_data = chart_spec.get("xAxis", {}).get("data", [])
                y_data = series_data.get("data", [])
                
                if x_data and y_data:
                    df = pd.DataFrame({
                        'category': x_data,
                        'value': y_data
                    })
                    return df
                    
            elif chart_type == 'pie':
                # é¥¼å›¾
                pie_data = series_data.get("data", [])
                if pie_data and isinstance(pie_data, list):
                    categories = []
                    values = []
                    for item in pie_data:
                        if isinstance(item, dict):
                            categories.append(item.get("name", ""))
                            values.append(item.get("value", 0))
                    
                    if categories and values:
                        df = pd.DataFrame({
                            'category': categories,
                            'value': values
                        })
                        return df
                        
            elif chart_type == 'scatter':
                # æ•£ç‚¹å›¾
                scatter_data = series_data.get("data", [])
                if scatter_data and isinstance(scatter_data, list):
                    x_values = []
                    y_values = []
                    for point in scatter_data:
                        if isinstance(point, list) and len(point) >= 2:
                            x_values.append(point[0])
                            y_values.append(point[1])
                    
                    if x_values and y_values:
                        df = pd.DataFrame({
                            'x': x_values,
                            'y': y_values
                        })
                        return df
            
            return None
            
        except Exception as e:
            logger.error(f"ä»å›¾è¡¨é…ç½®æå–æ•°æ®å¤±è´¥: {str(e)}")
            return None

    def _generate_insights_from_chart(self, chart_spec: Dict[str, Any], chart_type: str, original_df: pd.DataFrame) -> List[Dict[str, Any]]:
        """åŸºäºå›¾è¡¨é…ç½®ç”Ÿæˆæ•°æ®æ´å¯Ÿ"""
        insights = []
        
        try:
            # ä»å›¾è¡¨é…ç½®ä¸­æå–å®é™…æ•°æ®
            chart_df = self._extract_data_from_chart_spec(chart_spec, chart_type)
            logger.info(f"chart_df: {chart_df}")
            
            if chart_df is None or chart_df.empty:
                logger.warning("æ— æ³•ä»å›¾è¡¨é…ç½®ä¸­æå–æ•°æ®ï¼Œä½¿ç”¨åŸå§‹æ•°æ®ç”Ÿæˆæ´å¯Ÿ")
                return self._generate_insights(original_df)
            
            # ä½¿ç”¨DataInsightFrameworkåˆ†æå›¾è¡¨æ•°æ®
            framework = DataInsightFramework()
            
            # åˆ†ææ•°å€¼åˆ—
            numeric_cols = chart_df.select_dtypes(include=[np.number]).columns
            
            for col in numeric_cols:
                try:
                    # ä½¿ç”¨æ¡†æ¶åˆ†ææ¯ä¸ªæ•°å€¼åˆ—
                    framework_results = framework.analyze(chart_df, column=col)
                    
                    # è½¬æ¢æ¡†æ¶ç»“æœä¸ºå›¾è¡¨ç”Ÿæˆå™¨çš„æ ¼å¼
                    for result in framework_results:
                        insight = {
                            "type": result.insight_type,
                            "name": f"å›¾è¡¨æ•°æ® {col} - {result.algorithm}",
                            "description": f"[å›¾è¡¨æ•°æ®åˆ†æ] {result.description}",
                            "data": clean_numpy_types({
                                "algorithm": result.algorithm,
                                "severity": result.severity,
                                "confidence": result.confidence,
                                "details": result.details,
                                "affected_data": result.affected_data,
                                "recommendations": result.recommendations,
                                "chart_type": chart_type,
                                "data_source": "chart_data"
                            })
                        }
                        insights.append(insight)
                        
                except Exception as e:
                    logger.error(f"åˆ†æå›¾è¡¨æ•°æ®åˆ— {col} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            
            # å›¾è¡¨ç‰¹å®šçš„æ´å¯Ÿ
            chart_insights = self._generate_chart_specific_insights(chart_spec, chart_type, chart_df)
            insights.extend(chart_insights)
            
            # å¦‚æœæ²¡æœ‰ç”Ÿæˆä»»ä½•æ´å¯Ÿï¼Œæ·»åŠ åŸºæœ¬ä¿¡æ¯
            if not insights:
                insights.append({
                    "type": "chart_overview",
                    "name": f"{chart_type}å›¾è¡¨æ¦‚è§ˆ",
                    "description": f"å›¾è¡¨åŒ…å« {len(chart_df)} ä¸ªæ•°æ®ç‚¹",
                    "data": {
                        "chart_type": chart_type,
                        "data_points": len(chart_df),
                        "data_source": "chart_data"
                    }
                })
                
        except Exception as e:
            logger.error(f"åŸºäºå›¾è¡¨é…ç½®ç”Ÿæˆæ´å¯Ÿæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            # å›é€€åˆ°åŸå§‹æ•°æ®åˆ†æ
            return self._generate_insights(original_df)
        
        return insights

    def _generate_chart_specific_insights(self, chart_spec: Dict[str, Any], chart_type: str, chart_df: pd.DataFrame) -> List[Dict[str, Any]]:
        """ç”Ÿæˆå›¾è¡¨ç±»å‹ç‰¹å®šçš„æ´å¯Ÿ"""
        insights = []
        
        try:
            if chart_type in ['bar', 'line'] and 'value' in chart_df.columns:
                values = chart_df['value'].values
                
                # æ‰¾å‡ºæœ€é«˜å€¼å’Œæœ€ä½å€¼
                max_idx = np.argmax(values)
                min_idx = np.argmin(values)
                
                max_category = chart_df.iloc[max_idx]['category'] if 'category' in chart_df.columns else f"ä½ç½®{max_idx}"
                min_category = chart_df.iloc[min_idx]['category'] if 'category' in chart_df.columns else f"ä½ç½®{min_idx}"
                
                insights.append({
                    "type": "chart_analysis",
                    "name": f"{chart_type}å›¾è¡¨æ•°æ®åˆ†æ",
                    "description": f"æœ€é«˜å€¼å‡ºç°åœ¨ '{max_category}' ({values[max_idx]:.2f})ï¼Œæœ€ä½å€¼å‡ºç°åœ¨ '{min_category}' ({values[min_idx]:.2f})",
                    "data": {
                        "chart_type": chart_type,
                        "max_value": float(values[max_idx]),
                        "min_value": float(values[min_idx]),
                        "max_category": str(max_category),
                        "min_category": str(min_category),
                        "data_source": "chart_data"
                    }
                })
                
                # è®¡ç®—æ•°æ®åˆ†å¸ƒ
                mean_value = np.mean(values)
                std_value = np.std(values)
                cv = std_value / mean_value if mean_value != 0 else 0
                
                if cv > 0.5:
                    insights.append({
                        "type": "variability_analysis",
                        "name": "æ•°æ®æ³¢åŠ¨æ€§åˆ†æ",
                        "description": f"å›¾è¡¨æ•°æ®æ³¢åŠ¨è¾ƒå¤§ï¼Œå˜å¼‚ç³»æ•°ä¸º {cv:.3f}ï¼Œå»ºè®®å…³æ³¨æ•°æ®ç¨³å®šæ€§",
                        "data": {
                            "coefficient_of_variation": float(cv),
                            "mean": float(mean_value),
                            "std": float(std_value),
                            "data_source": "chart_data"
                        }
                    })
                    
            elif chart_type == 'pie' and 'value' in chart_df.columns:
                values = chart_df['value'].values
                total = np.sum(values)
                
                # æ‰¾å‡ºå æ¯”æœ€å¤§çš„ç±»åˆ«
                max_idx = np.argmax(values)
                max_category = chart_df.iloc[max_idx]['category'] if 'category' in chart_df.columns else f"ç±»åˆ«{max_idx}"
                max_percentage = (values[max_idx] / total) * 100
                
                insights.append({
                    "type": "proportion_analysis", 
                    "name": "é¥¼å›¾æ¯”ä¾‹åˆ†æ",
                    "description": f"'{max_category}' å æ®æœ€å¤§æ¯”ä¾‹ ({max_percentage:.1f}%)ï¼Œæ˜¯ä¸»è¦ç»„æˆéƒ¨åˆ†",
                    "data": {
                        "dominant_category": str(max_category),
                        "dominant_percentage": float(max_percentage),
                        "total_categories": len(values),
                        "data_source": "chart_data"
                    }
                })
                
        except Exception as e:
            logger.error(f"ç”Ÿæˆå›¾è¡¨ç‰¹å®šæ´å¯Ÿæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        
        return insights

    async def _generate_insight_markdown_from_chart(self, chart_spec: Dict[str, Any], insights: List[Dict], chart_type: str, use_llm: bool = False) -> str:
        """åŸºäºå›¾è¡¨é…ç½®ç”Ÿæˆæ´å¯Ÿæ–‡æ¡£ï¼ˆMarkdownæ ¼å¼ï¼‰"""
        md_content = []
        
        md_content.append("# å›¾è¡¨æ•°æ®åˆ†ææŠ¥å‘Š")
        md_content.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        md_content.append(f"**å›¾è¡¨ç±»å‹**: {chart_type}")
        md_content.append("")
        
        # å›¾è¡¨æ¦‚è§ˆ
        md_content.append("## å›¾è¡¨æ¦‚è§ˆ")
        series_count = len(chart_spec.get("series", []))
        md_content.append(f"- å›¾è¡¨ç³»åˆ—æ•°: {series_count}")
        
        if chart_spec.get("series"):
            first_series = chart_spec["series"][0]
            data_count = len(first_series.get("data", []))
            md_content.append(f"- æ•°æ®ç‚¹æ•°é‡: {data_count}")
            md_content.append(f"- ç³»åˆ—åç§°: {first_series.get('name', 'æœªå‘½å')}")
        
        md_content.append("")
        
        if insights:
            # æŒ‰æ•°æ®æºå’Œä¸¥é‡ç¨‹åº¦åˆ†ç»„æ˜¾ç¤ºæ´å¯Ÿ
            severity_order = {'critical': 'ğŸ”´ å…³é”®å‘ç°', 'high': 'ğŸŸ  é‡è¦å‘ç°', 'medium': 'ğŸŸ¡ ä¸€èˆ¬å‘ç°', 'low': 'ğŸŸ¢ åŸºç¡€ä¿¡æ¯'}
            
            # åˆ†ç»„æ´å¯Ÿ
            chart_insights = []
            framework_insights = {}
            
            for insight in insights:
                insight_data = insight.get('data', {})
                data_source = insight_data.get('data_source', 'unknown')
                
                if data_source == 'chart_data' and insight['type'] in ['chart_analysis', 'proportion_analysis', 'variability_analysis']:
                    chart_insights.append(insight)
                else:
                    severity = insight_data.get('severity', 'low')
                    if severity not in framework_insights:
                        framework_insights[severity] = []
                    framework_insights[severity].append(insight)
            
            # æ˜¾ç¤ºå›¾è¡¨ç‰¹å®šæ´å¯Ÿ
            if chart_insights:
                md_content.append("## ğŸ“Š å›¾è¡¨æ•°æ®æ´å¯Ÿ")
                for insight in chart_insights:
                    md_content.append(f"### {insight['name']}")
                    md_content.append(insight['description'])
                    md_content.append("")
            
            # æ˜¾ç¤ºæ¡†æ¶åˆ†æç»“æœ
            if framework_insights:
                md_content.append("## ğŸ” ä¸“ä¸šæ•°æ®åˆ†æ")
                for severity in ['critical', 'high', 'medium', 'low']:
                    if severity in framework_insights:
                        md_content.append(f"### {severity_order[severity]}")
                        for insight in framework_insights[severity]:
                            md_content.append(f"#### {insight['name']}")
                            md_content.append(insight['description'])
                            
                            insight_data = insight.get('data', {})
                            confidence = insight_data.get('confidence', 0)
                            algorithm = insight_data.get('algorithm', 'æœªçŸ¥')
                            
                            md_content.append(f"- **åˆ†æç®—æ³•**: {algorithm}")
                            md_content.append(f"- **ç½®ä¿¡åº¦**: {confidence:.2f}")
                            
                            # æ˜¾ç¤ºå»ºè®®
                            recommendations = insight_data.get('recommendations', [])
                            if recommendations:
                                md_content.append("- **å»ºè®®**:")
                                for rec in recommendations[:3]:
                                    md_content.append(f"  - {rec}")
                            
                            md_content.append("")
        
        # å›¾è¡¨è¯´æ˜
        md_content.append("## ğŸ“ˆ å›¾è¡¨è¯´æ˜")
        chart_descriptions = {
            'bar': "æŸ±çŠ¶å›¾é€‚åˆæ¯”è¾ƒä¸åŒç±»åˆ«çš„æ•°å€¼å¤§å°ï¼Œæœ¬åˆ†æåŸºäºå›¾è¡¨ä¸­å®é™…æ˜¾ç¤ºçš„æ•°æ®",
            'line': "æŠ˜çº¿å›¾é€‚åˆå±•ç¤ºæ•°æ®éšæ—¶é—´æˆ–å…¶ä»–è¿ç»­å˜é‡çš„å˜åŒ–è¶‹åŠ¿ï¼Œæœ¬åˆ†æåŸºäºå›¾è¡¨ä¸­å®é™…æ˜¾ç¤ºçš„æ•°æ®",
            'pie': "é¥¼å›¾é€‚åˆå±•ç¤ºå„éƒ¨åˆ†å æ•´ä½“çš„æ¯”ä¾‹å…³ç³»ï¼Œæœ¬åˆ†æåŸºäºå›¾è¡¨ä¸­å®é™…æ˜¾ç¤ºçš„æ•°æ®",
            'scatter': "æ•£ç‚¹å›¾é€‚åˆæ¢ç´¢ä¸¤ä¸ªæ•°å€¼å˜é‡ä¹‹é—´çš„ç›¸å…³å…³ç³»ï¼Œæœ¬åˆ†æåŸºäºå›¾è¡¨ä¸­å®é™…æ˜¾ç¤ºçš„æ•°æ®"
        }
        md_content.append(chart_descriptions.get(chart_type, "å›¾è¡¨å±•ç¤ºäº†æ•°æ®çš„å¯è§†åŒ–ç»“æœï¼Œæœ¬åˆ†æåŸºäºå›¾è¡¨ä¸­å®é™…æ˜¾ç¤ºçš„æ•°æ®"))
        
        # æ·»åŠ åˆ†æè¯´æ˜
        md_content.append("")
        md_content.append("## â„¹ï¸ åˆ†æè¯´æ˜")
        md_content.append("æœ¬æŠ¥å‘ŠåŸºäºå›¾è¡¨é…ç½®ä¸­çš„å®é™…æ•°æ®è¿›è¡Œåˆ†æï¼Œç¡®ä¿æ´å¯Ÿä¸å¯è§†åŒ–å†…å®¹å®Œå…¨ä¸€è‡´ã€‚")
        md_content.append("ä½¿ç”¨äº†ä¸“ä¸šçš„æ•°æ®æ´å¯Ÿæ¡†æ¶ï¼ŒåŒ…æ‹¬å¼‚å¸¸æ£€æµ‹ã€è¶‹åŠ¿åˆ†æã€ç›¸å…³æ€§åˆ†æç­‰å¤šç§ç®—æ³•ã€‚")
        
        # å¦‚æœå¯ç”¨LLMï¼Œä½¿ç”¨å¤§æ¨¡å‹ä¼˜åŒ–markdownå†…å®¹
        if use_llm:
            try:
                return await self._optimize_markdown_with_llm("\n".join(md_content), chart_spec, insights, chart_type)
            except Exception as e:
                logger.error(f"ä½¿ç”¨LLMä¼˜åŒ–markdownå¤±è´¥: {str(e)}ï¼Œè¿”å›åŸå§‹å†…å®¹")
                return "\n".join(md_content)
        
        return "\n".join(md_content) 