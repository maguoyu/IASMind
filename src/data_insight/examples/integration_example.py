#!/usr/bin/env python3
"""
æ•°æ®æ´å¯Ÿæ¡†æ¶é›†æˆç¤ºä¾‹
å±•ç¤ºå¦‚ä½•å°†æ•°æ®æ´å¯Ÿæ¡†æ¶ä¸å…¶ä»–åŠŸèƒ½æ¨¡å—ç»“åˆä½¿ç”¨
"""

import pandas as pd
import numpy as np
import json
from typing import Dict, List, Any
from datetime import datetime, timedelta
from src.data_insight import DataInsightFramework, InsightResult

class BusinessIntelligenceSystem:
    """
    ä¸šåŠ¡æ™ºèƒ½ç³»ç»Ÿ - é›†æˆæ•°æ®æ´å¯Ÿæ¡†æ¶
    """
    
    def __init__(self):
        self.insight_framework = DataInsightFramework()
        self.data_sources = {}
        self.insights_history = []
        self.alerts = []
    
    def register_data_source(self, name: str, data: pd.DataFrame):
        """æ³¨å†Œæ•°æ®æº"""
        self.data_sources[name] = data
        print(f"âœ“ æ•°æ®æº '{name}' å·²æ³¨å†Œï¼ŒåŒ…å« {len(data)} è¡Œæ•°æ®")
    
    def analyze_data_source(self, source_name: str, column: str = None) -> List[InsightResult]:
        """åˆ†ææŒ‡å®šæ•°æ®æº"""
        if source_name not in self.data_sources:
            raise ValueError(f"æ•°æ®æº '{source_name}' ä¸å­˜åœ¨")
        
        data = self.data_sources[source_name]
        insights = self.insight_framework.analyze(data, column=column)
        
        # è®°å½•æ´å¯Ÿå†å²
        analysis_record = {
            'timestamp': datetime.now().isoformat(),
            'source_name': source_name,
            'column': column,
            'insights_count': len(insights),
            'insights': [insight.to_dict() for insight in insights]
        }
        self.insights_history.append(analysis_record)
        
        # ç”Ÿæˆå‘Šè­¦
        self._generate_alerts(insights, source_name, column)
        
        return insights
    
    def _generate_alerts(self, insights: List[InsightResult], source_name: str, column: str):
        """åŸºäºæ´å¯Ÿç”Ÿæˆå‘Šè­¦"""
        high_severity_insights = [i for i in insights if i.severity in ['high', 'critical']]
        
        for insight in high_severity_insights:
            alert = {
                'timestamp': datetime.now().isoformat(),
                'source': source_name,
                'column': column,
                'type': insight.insight_type,
                'severity': insight.severity,
                'description': insight.description,
                'recommendations': insight.recommendations,
                'alert_id': f"ALERT_{len(self.alerts) + 1:04d}"
            }
            self.alerts.append(alert)
    
    def get_dashboard_summary(self) -> Dict[str, Any]:
        """è·å–ä»ªè¡¨ç›˜æ‘˜è¦"""
        total_insights = sum(len(record['insights']) for record in self.insights_history)
        active_alerts = len([a for a in self.alerts if self._is_alert_active(a)])
        
        # æŒ‰ç±»å‹ç»Ÿè®¡æ´å¯Ÿ
        insight_types = {}
        severity_counts = {}
        
        for record in self.insights_history:
            for insight_data in record['insights']:
                itype = insight_data['insight_type']
                severity = insight_data['severity']
                
                insight_types[itype] = insight_types.get(itype, 0) + 1
                severity_counts[severity] = severity_counts.get(severity, 0) + 1
        
        return {
            'summary': {
                'total_data_sources': len(self.data_sources),
                'total_insights': total_insights,
                'active_alerts': active_alerts,
                'analysis_runs': len(self.insights_history)
            },
            'insight_distribution': {
                'by_type': insight_types,
                'by_severity': severity_counts
            },
            'recent_alerts': self.alerts[-5:] if self.alerts else [],
            'data_sources': list(self.data_sources.keys())
        }
    
    def _is_alert_active(self, alert: Dict) -> bool:
        """åˆ¤æ–­å‘Šè­¦æ˜¯å¦ä»ç„¶æ´»è·ƒ"""
        alert_time = datetime.fromisoformat(alert['timestamp'])
        return datetime.now() - alert_time < timedelta(hours=24)
    
    def export_insights_report(self, filename: str = None) -> str:
        """å¯¼å‡ºæ´å¯ŸæŠ¥å‘Š"""
        if not filename:
            filename = f"insights_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        report = {
            'generated_at': datetime.now().isoformat(),
            'dashboard_summary': self.get_dashboard_summary(),
            'insights_history': self.insights_history,
            'alerts': self.alerts
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)
        
        return filename

class ChatBIAgent:
    """
    Chat BI ä»£ç† - ä¸æ•°æ®æ´å¯Ÿæ¡†æ¶é›†æˆ
    """
    
    def __init__(self, bi_system: BusinessIntelligenceSystem):
        self.bi_system = bi_system
        self.conversation_history = []
    
    def process_query(self, user_query: str) -> str:
        """å¤„ç†ç”¨æˆ·æŸ¥è¯¢"""
        query_lower = user_query.lower()
        
        # è®°å½•å¯¹è¯å†å²
        self.conversation_history.append({
            'timestamp': datetime.now().isoformat(),
            'user_query': user_query,
            'response': None
        })
        
        response = ""
        
        # è§£ææŸ¥è¯¢æ„å›¾
        if "å¼‚å¸¸" in query_lower or "anomaly" in query_lower:
            response = self._handle_anomaly_query(user_query)
        elif "è¶‹åŠ¿" in query_lower or "trend" in query_lower:
            response = self._handle_trend_query(user_query)
        elif "ç›¸å…³" in query_lower or "correlation" in query_lower:
            response = self._handle_correlation_query(user_query)
        elif "æ‘˜è¦" in query_lower or "summary" in query_lower:
            response = self._handle_summary_query(user_query)
        elif "å‘Šè­¦" in query_lower or "alert" in query_lower:
            response = self._handle_alert_query(user_query)
        else:
            response = self._handle_general_query(user_query)
        
        # æ›´æ–°å¯¹è¯å†å²
        self.conversation_history[-1]['response'] = response
        
        return response
    
    def _handle_anomaly_query(self, query: str) -> str:
        """å¤„ç†å¼‚å¸¸æ£€æµ‹æŸ¥è¯¢"""
        anomaly_insights = []
        
        for record in self.bi_system.insights_history:
            for insight_data in record['insights']:
                if insight_data['insight_type'] == 'anomaly':
                    anomaly_insights.append({
                        'source': record['source_name'],
                        'column': record['column'],
                        'algorithm': insight_data['algorithm'],
                        'description': insight_data['description'],
                        'severity': insight_data['severity']
                    })
        
        if not anomaly_insights:
            return "å½“å‰æ²¡æœ‰æ£€æµ‹åˆ°å¼‚å¸¸æ•°æ®ã€‚"
        
        response = f"æ£€æµ‹åˆ° {len(anomaly_insights)} ä¸ªå¼‚å¸¸æƒ…å†µï¼š\n\n"
        for i, anomaly in enumerate(anomaly_insights[-5:], 1):  # æ˜¾ç¤ºæœ€è¿‘5ä¸ª
            response += f"{i}. ã€{anomaly['source']} - {anomaly['column']}ã€‘\n"
            response += f"   ç®—æ³•: {anomaly['algorithm']}\n"
            response += f"   æè¿°: {anomaly['description']}\n"
            response += f"   ä¸¥é‡ç¨‹åº¦: {anomaly['severity']}\n\n"
        
        return response
    
    def _handle_trend_query(self, query: str) -> str:
        """å¤„ç†è¶‹åŠ¿åˆ†ææŸ¥è¯¢"""
        trend_insights = []
        
        for record in self.bi_system.insights_history:
            for insight_data in record['insights']:
                if insight_data['insight_type'] == 'trend':
                    trend_insights.append({
                        'source': record['source_name'],
                        'column': record['column'],
                        'description': insight_data['description'],
                        'details': insight_data.get('details', {})
                    })
        
        if not trend_insights:
            return "å½“å‰æ²¡æœ‰æ£€æµ‹åˆ°æ˜¾è‘—è¶‹åŠ¿ã€‚"
        
        response = f"æ£€æµ‹åˆ° {len(trend_insights)} ä¸ªè¶‹åŠ¿ï¼š\n\n"
        for i, trend in enumerate(trend_insights, 1):
            response += f"{i}. ã€{trend['source']} - {trend['column']}ã€‘\n"
            response += f"   {trend['description']}\n"
            if 'trend' in trend['details']:
                response += f"   è¶‹åŠ¿æ–¹å‘: {trend['details']['trend']}\n"
            if 'slope' in trend['details']:
                response += f"   å˜åŒ–æ–œç‡: {trend['details']['slope']:.4f}\n"
            response += "\n"
        
        return response
    
    def _handle_correlation_query(self, query: str) -> str:
        """å¤„ç†ç›¸å…³æ€§åˆ†ææŸ¥è¯¢"""
        correlation_insights = []
        
        for record in self.bi_system.insights_history:
            for insight_data in record['insights']:
                if insight_data['insight_type'] == 'relationship':
                    correlation_insights.append({
                        'source': record['source_name'],
                        'description': insight_data['description'],
                        'details': insight_data.get('details', {})
                    })
        
        if not correlation_insights:
            return "å½“å‰æ²¡æœ‰å‘ç°æ˜¾è‘—çš„å˜é‡ç›¸å…³æ€§ã€‚"
        
        response = "å‘ç°ä»¥ä¸‹ç›¸å…³æ€§ï¼š\n\n"
        for i, corr in enumerate(correlation_insights, 1):
            response += f"{i}. ã€{corr['source']}ã€‘{corr['description']}\n"
            
            if 'strong_correlations' in corr['details']:
                for sc in corr['details']['strong_correlations']:
                    response += f"   â€¢ {sc['col1']} â†” {sc['col2']}\n"
                    response += f"     Pearson: {sc['pearson']:.3f}, Spearman: {sc['spearman']:.3f}\n"
            response += "\n"
        
        return response
    
    def _handle_summary_query(self, query: str) -> str:
        """å¤„ç†æ‘˜è¦æŸ¥è¯¢"""
        summary = self.bi_system.get_dashboard_summary()
        
        response = "ğŸ“Š æ•°æ®æ´å¯Ÿæ‘˜è¦æŠ¥å‘Š\n"
        response += "=" * 30 + "\n\n"
        
        response += f"æ•°æ®æºæ•°é‡: {summary['summary']['total_data_sources']}\n"
        response += f"æ€»æ´å¯Ÿæ•°: {summary['summary']['total_insights']}\n"
        response += f"æ´»è·ƒå‘Šè­¦: {summary['summary']['active_alerts']}\n"
        response += f"åˆ†ææ¬¡æ•°: {summary['summary']['analysis_runs']}\n\n"
        
        if summary['insight_distribution']['by_type']:
            response += "æ´å¯Ÿç±»å‹åˆ†å¸ƒ:\n"
            for itype, count in summary['insight_distribution']['by_type'].items():
                response += f"  â€¢ {itype}: {count}\n"
            response += "\n"
        
        if summary['insight_distribution']['by_severity']:
            response += "ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ:\n"
            for severity, count in summary['insight_distribution']['by_severity'].items():
                response += f"  â€¢ {severity}: {count}\n"
        
        return response
    
    def _handle_alert_query(self, query: str) -> str:
        """å¤„ç†å‘Šè­¦æŸ¥è¯¢"""
        active_alerts = [a for a in self.bi_system.alerts if self.bi_system._is_alert_active(a)]
        
        if not active_alerts:
            return "å½“å‰æ²¡æœ‰æ´»è·ƒçš„å‘Šè­¦ã€‚"
        
        response = f"ğŸš¨ æ´»è·ƒå‘Šè­¦ ({len(active_alerts)} ä¸ª):\n\n"
        for alert in active_alerts:
            response += f"â€¢ {alert['alert_id']} - {alert['type'].upper()}\n"
            response += f"  æ•°æ®æº: {alert['source']} - {alert['column']}\n"
            response += f"  ä¸¥é‡ç¨‹åº¦: {alert['severity']}\n"
            response += f"  æè¿°: {alert['description']}\n"
            if alert['recommendations']:
                response += f"  å»ºè®®: {alert['recommendations'][0]}\n"
            response += "\n"
        
        return response
    
    def _handle_general_query(self, query: str) -> str:
        """å¤„ç†ä¸€èˆ¬æŸ¥è¯¢"""
        return f"""æˆ‘å¯ä»¥å¸®æ‚¨åˆ†æä»¥ä¸‹å†…å®¹ï¼š

â€¢ å¼‚å¸¸æ£€æµ‹ - è¯¢é—® "æœ‰ä»€ä¹ˆå¼‚å¸¸ï¼Ÿ"
â€¢ è¶‹åŠ¿åˆ†æ - è¯¢é—® "æ•°æ®è¶‹åŠ¿å¦‚ä½•ï¼Ÿ"  
â€¢ ç›¸å…³æ€§åˆ†æ - è¯¢é—® "å˜é‡ä¹‹é—´æœ‰ä»€ä¹ˆç›¸å…³æ€§ï¼Ÿ"
â€¢ æ‘˜è¦æŠ¥å‘Š - è¯¢é—® "ç»™æˆ‘ä¸€ä¸ªæ‘˜è¦"
â€¢ å‘Šè­¦ä¿¡æ¯ - è¯¢é—® "æœ‰ä»€ä¹ˆå‘Šè­¦ï¼Ÿ"

æ‚¨çš„é—®é¢˜: {query}

å¦‚æœæ‚¨æƒ³åˆ†æç‰¹å®šæ•°æ®ï¼Œè¯·å…ˆç¡®ä¿æ•°æ®æºå·²æ³¨å†Œåˆ°ç³»ç»Ÿä¸­ã€‚
å½“å‰å¯ç”¨æ•°æ®æº: {', '.join(self.bi_system.data_sources.keys())}"""

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºå®Œæ•´çš„é›†æˆæµç¨‹"""
    print("=" * 60)
    print("æ•°æ®æ´å¯Ÿæ¡†æ¶é›†æˆç¤ºä¾‹")
    print("=" * 60)
    
    # 1. åˆ›å»ºä¸šåŠ¡æ™ºèƒ½ç³»ç»Ÿ
    bi_system = BusinessIntelligenceSystem()
    
    # 2. åˆ›å»ºæ¨¡æ‹Ÿä¸šåŠ¡æ•°æ®
    np.random.seed(42)
    
    # é”€å”®æ•°æ®
    dates = pd.date_range('2023-01-01', periods=100, freq='D')
    sales = 1000 + np.cumsum(np.random.randn(100) * 10)
    sales[20] = 2000  # å¼‚å¸¸ç‚¹
    sales[80] = 300   # å¼‚å¸¸ç‚¹
    
    sales_data = pd.DataFrame({
        'date': dates,
        'revenue': sales,
        'orders': sales / 50 + np.random.randn(100) * 5,
        'customers': sales / 100 + np.random.randn(100) * 2
    })
    
    # ç”¨æˆ·æ´»è·ƒåº¦æ•°æ®
    user_activity = pd.DataFrame({
        'date': dates,
        'daily_active_users': sales * 0.8 + np.random.randn(100) * 20,
        'session_duration': 300 + np.random.randn(100) * 50,
        'page_views': sales * 2 + np.random.randn(100) * 100
    })
    
    # 3. æ³¨å†Œæ•°æ®æº
    bi_system.register_data_source('sales', sales_data)
    bi_system.register_data_source('user_activity', user_activity)
    
    # 4. æ‰§è¡Œæ•°æ®åˆ†æ
    print("\næ‰§è¡Œæ•°æ®åˆ†æ...")
    sales_insights = bi_system.analyze_data_source('sales', 'revenue')
    user_insights = bi_system.analyze_data_source('user_activity', 'daily_active_users')
    
    print(f"é”€å”®æ•°æ®æ´å¯Ÿ: {len(sales_insights)} ä¸ª")
    print(f"ç”¨æˆ·æ´»è·ƒåº¦æ´å¯Ÿ: {len(user_insights)} ä¸ª")
    
    # 5. åˆ›å»ºChat BIä»£ç†
    chat_agent = ChatBIAgent(bi_system)
    
    # 6. æ¨¡æ‹Ÿç”¨æˆ·å¯¹è¯
    print("\n" + "=" * 60)
    print("Chat BI å¯¹è¯æ¨¡æ‹Ÿ")
    print("=" * 60)
    
    queries = [
        "ç»™æˆ‘ä¸€ä¸ªæ•°æ®æ‘˜è¦",
        "æœ‰ä»€ä¹ˆå¼‚å¸¸æƒ…å†µå—ï¼Ÿ",
        "æ•°æ®è¶‹åŠ¿å¦‚ä½•ï¼Ÿ",
        "æœ‰ä»€ä¹ˆå‘Šè­¦å—ï¼Ÿ",
        "å˜é‡ä¹‹é—´æœ‰ç›¸å…³æ€§å—ï¼Ÿ"
    ]
    
    for query in queries:
        print(f"\nç”¨æˆ·: {query}")
        print("-" * 40)
        response = chat_agent.process_query(query)
        print(f"åŠ©æ‰‹: {response}")
    
    # 7. ç”Ÿæˆä»ªè¡¨ç›˜æ‘˜è¦
    print("\n" + "=" * 60)
    print("ä»ªè¡¨ç›˜æ‘˜è¦")
    print("=" * 60)
    dashboard = bi_system.get_dashboard_summary()
    print(json.dumps(dashboard, indent=2, ensure_ascii=False, default=str))
    
    # 8. å¯¼å‡ºæŠ¥å‘Š
    print("\n" + "=" * 60)
    print("å¯¼å‡ºæŠ¥å‘Š")
    print("=" * 60)
    report_file = bi_system.export_insights_report()
    print(f"âœ“ æ´å¯ŸæŠ¥å‘Šå·²å¯¼å‡ºåˆ°: {report_file}")
    
    print(f"\nåˆ†æå®Œæˆï¼ç³»ç»Ÿå…±:")
    print(f"  â€¢ å¤„ç†äº† {len(bi_system.data_sources)} ä¸ªæ•°æ®æº")
    print(f"  â€¢ ç”Ÿæˆäº† {sum(len(record['insights']) for record in bi_system.insights_history)} ä¸ªæ´å¯Ÿ")
    print(f"  â€¢ äº§ç”Ÿäº† {len(bi_system.alerts)} ä¸ªå‘Šè­¦")
    print(f"  â€¢ è¿›è¡Œäº† {len(chat_agent.conversation_history)} è½®å¯¹è¯")

if __name__ == "__main__":
    main() 