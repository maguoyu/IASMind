# Copyright (c) 2025 Bytedance Ltd. and/or its affiliates
# SPDX-License-Identifier: MIT

from fastapi import APIRouter, HTTPException, Depends
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import Optional, Dict, Any, List, Union
import json
import asyncio
from uuid import uuid4
from datetime import datetime

from src.database_analysis.graph.builder import run_database_analysis
from ..auth_middleware import GetCurrentUser

# åˆ›å»ºè·¯ç”±å™¨
router = APIRouter(prefix="/api/database_analysis", tags=["database_analysis"])


class DatabaseAnalysisRequest(BaseModel):
    """æ•°æ®åº“åˆ†æè¯·æ±‚"""
    user_query: str
    datasource_id: str
    thread_id: str
    table_name: Optional[str] = None
    enable_insights: bool = False


class TableData(BaseModel):
    """è¡¨æ ¼æ•°æ®ç»“æ„"""
    data: List[Dict[str, Any]]
    columns: List[str]


class TextData(BaseModel):
    """æ–‡æœ¬æ•°æ®ç»“æ„"""
    summary: str
    details: List[Dict[str, Any]]


class DatabaseAnalysisResponse(BaseModel):
    """æ•°æ®åº“åˆ†æå“åº”"""
    success: bool
    result_type: str  # chart, table, text
    data: Optional[Union[TableData, TextData]] = None
    chart_config: Optional[Dict[str, Any]] = None
    error: Optional[str] = None
    metadata: Optional[Dict[str, Any]] = None
    insights: Optional[Dict[str, Any]] = None
    insight_md: Optional[str] = None


def generate_echarts_spec(chart_config: Dict[str, Any], data: List[Dict[str, Any]], columns: List[str]) -> Dict[str, Any]:
    """
    æ ¹æ®å›¾è¡¨é…ç½®ç”ŸæˆEChartsæ ¼å¼çš„spec
    
    Args:
        chart_config: å›¾è¡¨é…ç½®
        data: æ•°æ®åˆ—è¡¨
        columns: åˆ—ååˆ—è¡¨
        
    Returns:
        EChartsæ ¼å¼çš„specé…ç½®
    """
    if not data or not chart_config:
        return {}
    
    chart_type = chart_config.get("type", "table")
    
    # å¦‚æœæ˜¯è¡¨æ ¼ç±»å‹ï¼Œè¿”å›è¡¨æ ¼é…ç½®
    if chart_type == "table":
        return {
            "type": "table",
            "columns": columns
        }
    
    # åŸºç¡€EChartsé…ç½®
    base_config = {
        "title": {"text": "æ•°æ®åˆ†æå›¾è¡¨", "left": "center"},
        "tooltip": {"trigger": "axis" if chart_type in ['line', 'bar'] else "item"},
        "legend": {"orient": "horizontal", "left": "center", "bottom": "10%"},
        "toolbox": {
            "show": True,
            "feature": {
                "dataView": {"show": True, "readOnly": False},
                "magicType": {"show": True, "type": ["line", "bar"]},
                "restore": {"show": True},
                "saveAsImage": {"show": True}
            }
        }
    }
    
    # æ ¹æ®å›¾è¡¨ç±»å‹ç”Ÿæˆå¯¹åº”çš„EChartsé…ç½®
    if chart_type == "bar":
        x_field = chart_config.get("x", columns[0] if columns else "category")
        y_field = chart_config.get("y", columns[1] if len(columns) > 1 else "value")
        
        return {
            **base_config,
            "xAxis": {"type": "category", "data": [item.get(x_field, '') for item in data]},
            "yAxis": {"type": "value"},
            "series": [{
                "name": y_field,
                "type": "bar",
                "data": [item.get(y_field, 0) for item in data],
                "itemStyle": {"color": "#5470c6"}
            }]
        }
        
    elif chart_type == "line":
        x_field = chart_config.get("x", columns[0] if columns else "category")
        y_field = chart_config.get("y", columns[1] if len(columns) > 1 else "value")
        
        return {
            **base_config,
            "xAxis": {"type": "category", "data": [item.get(x_field, '') for item in data]},
            "yAxis": {"type": "value"},
            "series": [{
                "name": y_field,
                "type": "line",
                "data": [item.get(y_field, 0) for item in data],
                "smooth": True,
                "lineStyle": {"color": "#5470c6"}
            }]
        }
        
    elif chart_type == "pie":
        category_field = chart_config.get("x", columns[0] if columns else "category")
        value_field = chart_config.get("y", columns[1] if len(columns) > 1 else "value")
        
        return {
            **base_config,
            "series": [{
                "name": "æ•°æ®",
                "type": "pie",
                "radius": "50%",
                "data": [{"name": item.get(category_field, ''), "value": item.get(value_field, 0)} for item in data],
                "emphasis": {
                    "itemStyle": {
                        "shadowBlur": 10,
                        "shadowOffsetX": 0,
                        "shadowColor": "rgba(0, 0, 0, 0.5)"
                    }
                }
            }]
        }
        
    elif chart_type == "scatter":
        x_field = chart_config.get("x", columns[0] if columns else "x")
        y_field = chart_config.get("y", columns[1] if len(columns) > 1 else "y")
        
        return {
            **base_config,
            "xAxis": {"type": "value", "name": x_field},
            "yAxis": {"type": "value", "name": y_field},
            "series": [{
                "name": "æ•°æ®ç‚¹",
                "type": "scatter",
                "data": [[item.get(x_field, 0), item.get(y_field, 0)] for item in data],
                "symbolSize": 8,
                "itemStyle": {"color": "#5470c6"}
            }]
        }
        
    elif chart_type == "area":
        x_field = chart_config.get("x", columns[0] if columns else "category")
        y_field = chart_config.get("y", columns[1] if len(columns) > 1 else "value")
        
        return {
            **base_config,
            "xAxis": {"type": "category", "data": [item.get(x_field, '') for item in data]},
            "yAxis": {"type": "value"},
            "series": [{
                "name": y_field,
                "type": "line",
                "data": [item.get(y_field, 0) for item in data],
                "areaStyle": {},  # æ·»åŠ åŒºåŸŸå¡«å……
                "smooth": True,
                "lineStyle": {"color": "#5470c6"}
            }]
        }
    
    # é»˜è®¤è¿”å›æŸ±çŠ¶å›¾
    x_field = columns[0] if columns else "category"
    y_field = columns[1] if len(columns) > 1 else "value"
    return {
        **base_config,
        "xAxis": {"type": "category", "data": [item.get(x_field, '') for item in data]},
        "yAxis": {"type": "value"},
        "series": [{
            "name": y_field,
            "type": "bar",
            "data": [item.get(y_field, 0) for item in data],
            "itemStyle": {"color": "#5470c6"}
        }]
    }


def generate_database_insight_markdown(
    data: List[Dict[str, Any]], 
    columns: List[str], 
    metadata: Dict[str, Any], 
    insights_data: Optional[Dict[str, Any]] = None
) -> str:
    """ç”Ÿæˆæ•°æ®åº“åˆ†ææ´å¯Ÿçš„Markdownæ–‡æ¡£"""
    md_content = []
    
    md_content.append("# æ•°æ®åº“æŸ¥è¯¢åˆ†ææŠ¥å‘Š")
    md_content.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    md_content.append(f"**æŸ¥è¯¢æ‰§è¡Œæ—¶é—´**: {metadata.get('execution_time', 0):.3f}ç§’")
    md_content.append("")
    
    # æŸ¥è¯¢æ¦‚è§ˆ
    md_content.append("## æŸ¥è¯¢æ¦‚è§ˆ")
    md_content.append(f"- æŸ¥è¯¢ç»“æœ: {metadata.get('row_count', 0)} æ¡è®°å½•")
    md_content.append(f"- å­—æ®µæ•°é‡: {len(columns)}")
    md_content.append(f"- æ¶‰åŠè¡¨: {', '.join(metadata.get('tables', []))}")
    md_content.append(f"- å­—æ®µåˆ—è¡¨: {', '.join(columns)}")
    md_content.append("")
    
    # SQLæŸ¥è¯¢
    if metadata.get('sql_query'):
        md_content.append("## SQLæŸ¥è¯¢è¯­å¥")
        md_content.append("```sql")
        md_content.append(metadata['sql_query'])
        md_content.append("```")
        md_content.append("")
    
    # æ•°æ®æ´å¯Ÿ
    if insights_data:
        md_content.append("## æ•°æ®æ´å¯Ÿåˆ†æ")
        
        # åŸºç¡€æ´å¯Ÿ
        if insights_data.get('basic_insights'):
            md_content.append("### ğŸ“Š åŸºç¡€ç»Ÿè®¡åˆ†æ")
            for insight in insights_data['basic_insights']:
                md_content.append(f"- {insight}")
            md_content.append("")
        
        # é«˜çº§æ´å¯Ÿ
        if insights_data.get('advanced_insights'):
            md_content.append("### ğŸ” ä¸“ä¸šæ•°æ®æ´å¯Ÿ")
            
            # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç»„æ˜¾ç¤º
            severity_order = {'critical': 'ğŸ”´ å…³é”®é—®é¢˜', 'high': 'ğŸŸ  é‡è¦å‘ç°', 'medium': 'ğŸŸ¡ ä¸€èˆ¬å‘ç°', 'low': 'ğŸŸ¢ åŸºç¡€ä¿¡æ¯'}
            insights_by_severity = {}
            
            for insight in insights_data['advanced_insights']:
                severity = insight.get('severity', 'low')
                if severity not in insights_by_severity:
                    insights_by_severity[severity] = []
                insights_by_severity[severity].append(insight)
            
            for severity in ['critical', 'high', 'medium', 'low']:
                if severity in insights_by_severity:
                    md_content.append(f"#### {severity_order[severity]}")
                    for insight in insights_by_severity[severity]:
                        md_content.append(f"**{insight['column']}å­—æ®µåˆ†æ**")
                        md_content.append(f"- {insight['description']}")
                        md_content.append(f"- ç½®ä¿¡åº¦: {insight.get('confidence', 0):.2f}")
                        md_content.append(f"- åˆ†æç±»å‹: {insight.get('type', 'æœªçŸ¥')}")
                        md_content.append("")
    
    # æ•°æ®æ ·ä¾‹ï¼ˆæ˜¾ç¤ºå‰5è¡Œï¼‰
    if data and len(data) > 0:
        md_content.append("## æ•°æ®æ ·ä¾‹")
        md_content.append("ä»¥ä¸‹æ˜¯æŸ¥è¯¢ç»“æœçš„å‰5è¡Œæ•°æ®ï¼š")
        md_content.append("")
        
        # åˆ›å»ºè¡¨æ ¼å¤´
        md_content.append("| " + " | ".join(columns) + " |")
        md_content.append("| " + " | ".join(["---"] * len(columns)) + " |")
        
        # æ·»åŠ æ•°æ®è¡Œï¼ˆæœ€å¤š5è¡Œï¼‰
        for i, row in enumerate(data[:5]):
            row_values = []
            for col in columns:
                value = row.get(col, "")
                # å¤„ç†Noneå€¼å’Œé•¿å­—ç¬¦ä¸²
                if value is None:
                    value = "NULL"
                elif isinstance(value, str) and len(value) > 20:
                    value = value[:17] + "..."
                row_values.append(str(value))
            md_content.append("| " + " | ".join(row_values) + " |")
            
        if len(data) > 5:
            md_content.append("")
            md_content.append(f"*è¿˜æœ‰ {len(data) - 5} è¡Œæ•°æ®æœªæ˜¾ç¤º*")
        md_content.append("")
    
    # æ•°æ®è´¨é‡è¯„ä¼°
    if data and insights_data:
        md_content.append("## æ•°æ®è´¨é‡è¯„ä¼°")
        
        # è®¡ç®—åŸºç¡€è´¨é‡æŒ‡æ ‡
        total_records = len(data)
        total_fields = len(columns)
        
        # æ£€æŸ¥ç©ºå€¼
        null_counts = {}
        for col in columns:
            null_count = sum(1 for row in data if row.get(col) is None or row.get(col) == "")
            if null_count > 0:
                null_counts[col] = null_count
        
        if null_counts:
            md_content.append("### ç¼ºå¤±å€¼åˆ†æ")
            for col, count in null_counts.items():
                percentage = (count / total_records) * 100
                md_content.append(f"- **{col}**: {count} ä¸ªç¼ºå¤±å€¼ ({percentage:.1f}%)")
        else:
            md_content.append("### âœ… æ•°æ®å®Œæ•´æ€§è‰¯å¥½")
            md_content.append("- æœªå‘ç°ç¼ºå¤±å€¼")
        
        md_content.append("")
    
    # å»ºè®®ä¸æ€»ç»“
    md_content.append("## åˆ†æå»ºè®®")
    if insights_data and insights_data.get('advanced_insights'):
        high_severity_count = len([i for i in insights_data['advanced_insights'] if i.get('severity') in ['high', 'critical']])
        if high_severity_count > 0:
            md_content.append(f"- å‘ç° {high_severity_count} ä¸ªéœ€è¦å…³æ³¨çš„æ•°æ®é—®é¢˜ï¼Œå»ºè®®è¿›ä¸€æ­¥è°ƒæŸ¥")
        else:
            md_content.append("- æ•°æ®è´¨é‡æ•´ä½“è‰¯å¥½ï¼Œæœªå‘ç°æ˜æ˜¾å¼‚å¸¸")
    else:
        md_content.append("- å»ºè®®å¯ç”¨æ•°æ®æ´å¯ŸåŠŸèƒ½ä»¥è·å¾—æ›´è¯¦ç»†çš„åˆ†æ")
    
    md_content.append("- å®šæœŸç›‘æ§æ•°æ®å˜åŒ–ï¼Œç¡®ä¿æ•°æ®è´¨é‡ç¨³å®š")
    md_content.append("- è€ƒè™‘å»ºç«‹æ•°æ®è´¨é‡ç›‘æ§æœºåˆ¶")
    md_content.append("")
    
    md_content.append("---")
    md_content.append("*æœ¬æŠ¥å‘Šç”±IASMindæ•°æ®åˆ†æç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*")
    
    return "\n".join(md_content)


@router.post("/analyze", response_model=DatabaseAnalysisResponse)
async def analyze_database(
    request: DatabaseAnalysisRequest,
    user_info: dict = Depends(GetCurrentUser)
):
    """
    æ•°æ®åº“æ•°æ®åˆ†ææ¥å£
    
    åŠŸèƒ½æµç¨‹ï¼š
    1. æŸ¥è¯¢è¾“å…¥ â†’ é¢„å¤„ç† â†’ å®ä½“è¯†åˆ« â†’ å…ƒæ•°æ®æ£€ç´¢ 
    2. SQLç”Ÿæˆ â†’ éªŒè¯ â†’ æ‰§è¡Œ â†’ ç»“æœè¿”å› 
    3. åˆ¤æ–­æ˜¾ç¤ºç±»å‹ï¼ˆå›¾è¡¨ã€è¡¨æ ¼æˆ–çº¯æ–‡æœ¬ï¼‰â†’ é¡µé¢æ˜¾ç¤º
    """
    try:
        # ç”Ÿæˆçº¿ç¨‹ID
        thread_id = request.thread_id
        if thread_id == "__default__":
            thread_id = str(uuid4())
        
        # æ‰§è¡Œåˆ†æ
        result = await run_database_analysis(
            user_query=request.user_query,
            datasource_id=request.datasource_id,
            table_name=request.table_name,
            thread_id=thread_id
        )
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
        if result.get("error"):
            return DatabaseAnalysisResponse(
                success=False,
                result_type="text",
                error=result["error"]
            )
        
        # æ„å»ºå“åº”
        response_data = {
            "success": True,
            "result_type": result.get("result_type", "table"),
            "metadata": {
                "sql_query": result.get("sql_query", ""),
                "execution_time": result.get("query_result", {}).get("execution_time", 0),
                "row_count": result.get("query_result", {}).get("row_count", 0),
                "entities": result.get("entities", []),
                "tables": [table.get("name", "") for table in result.get("metadata", {}).get("tables", [])]
            }
        }
        
        # æ ¹æ®ç»“æœç±»å‹è¿”å›ä¸åŒæ•°æ®
        result_type = result.get("result_type", "table")
        query_result = result.get("query_result", {})
        
        # å¦‚æœå¯ç”¨äº†æ•°æ®æ´å¯Ÿï¼Œç”Ÿæˆæ´å¯Ÿä¿¡æ¯
        insights_data = None
        if request.enable_insights and query_result.get("data"):
            try:
                from src.data_insight.data_insight_framework import DataInsightFramework
                import pandas as pd
                
                # å°†æŸ¥è¯¢ç»“æœè½¬æ¢ä¸ºDataFrame
                data = query_result.get("data", [])
                columns = query_result.get("columns", [])
                
                if data and columns:
                    df = pd.DataFrame(data, columns=columns)
                    
                    # åˆ›å»ºæ•°æ®æ´å¯Ÿæ¡†æ¶å®ä¾‹
                    framework = DataInsightFramework()
                    
                    # åˆ†ææ•°å€¼åˆ—
                    numeric_cols = df.select_dtypes(include=['number']).columns
                    insights_results = []
                    
                    for col in numeric_cols:
                        try:
                            # ä½¿ç”¨æ¡†æ¶åˆ†ææ¯ä¸ªæ•°å€¼åˆ—
                            framework_results = framework.analyze(df, column=col)
                            
                            # è½¬æ¢æ¡†æ¶ç»“æœä¸ºç®€åŒ–çš„æ´å¯Ÿä¿¡æ¯
                            for insight_result in framework_results:
                                if insight_result.severity in ['medium', 'high', 'critical']:  # åªåŒ…å«é‡è¦æ´å¯Ÿ
                                    insights_results.append({
                                        "type": insight_result.insight_type,
                                        "column": col,
                                        "description": insight_result.description,
                                        "severity": insight_result.severity,
                                        "confidence": insight_result.confidence
                                    })
                        except Exception as e:
                            print(f"åˆ†æåˆ— {col} æ—¶å‡ºé”™: {str(e)}")
                    
                    # ç”ŸæˆåŸºç¡€ç»Ÿè®¡æ´å¯Ÿ
                    basic_insights = []
                    if len(data) > 0:
                        basic_insights.append(f"æŸ¥è¯¢è¿”å› {len(data)} æ¡è®°å½•")
                        basic_insights.append(f"åŒ…å« {len(numeric_cols)} ä¸ªæ•°å€¼å­—æ®µ: {', '.join(numeric_cols)}")
                        
                        # æ·»åŠ æ•°æ®åˆ†å¸ƒæ´å¯Ÿ
                        for col in numeric_cols:
                            col_data = df[col].dropna()
                            if len(col_data) > 0:
                                mean_val = col_data.mean()
                                std_val = col_data.std()
                                if std_val > mean_val * 0.5:  # å¦‚æœæ ‡å‡†å·®è¾ƒå¤§
                                    basic_insights.append(f"{col} å­—æ®µæ•°æ®åˆ†å¸ƒè¾ƒä¸ºåˆ†æ•£ï¼Œæ ‡å‡†å·®ä¸º {std_val:.2f}")
                                
                                # æ£€æŸ¥æ˜¯å¦æœ‰æ˜æ˜¾çš„å¼‚å¸¸å€¼
                                q75, q25 = col_data.quantile(0.75), col_data.quantile(0.25)
                                iqr = q75 - q25
                                outliers = col_data[(col_data < (q25 - 1.5 * iqr)) | (col_data > (q75 + 1.5 * iqr))]
                                if len(outliers) > 0:
                                    basic_insights.append(f"{col} å­—æ®µæ£€æµ‹åˆ° {len(outliers)} ä¸ªæ½œåœ¨å¼‚å¸¸å€¼")
                    
                    insights_data = {
                        "basic_insights": basic_insights,
                        "advanced_insights": insights_results
                    }
                    
            except ImportError:
                print("è­¦å‘Š: æ•°æ®æ´å¯Ÿæ¡†æ¶ä¸å¯ç”¨ï¼Œè·³è¿‡æ´å¯Ÿç”Ÿæˆ")
            except Exception as e:
                print(f"ç”Ÿæˆæ•°æ®æ´å¯Ÿæ—¶å‡ºé”™: {str(e)}")
        
        # å°†æ´å¯Ÿæ•°æ®æ·»åŠ åˆ°å“åº”ä¸­
        if insights_data:
            response_data["insights"] = insights_data
            
            # ç”ŸæˆMarkdownæ ¼å¼çš„æ´å¯ŸæŠ¥å‘Š
            try:
                insight_md = generate_database_insight_markdown(
                    data=query_result.get("data", []),
                    columns=query_result.get("columns", []),
                    metadata={
                        "sql_query": result.get("sql_query", ""),
                        "execution_time": query_result.get("execution_time", 0),
                        "row_count": query_result.get("row_count", 0),
                        "entities": result.get("entities", []),
                        "tables": [table.get("name", "") for table in result.get("metadata", {}).get("tables", [])]
                    },
                    insights_data=insights_data
                )
                response_data["insight_md"] = insight_md
            except Exception as e:
                print(f"ç”ŸæˆMarkdownæ´å¯ŸæŠ¥å‘Šæ—¶å‡ºé”™: {str(e)}")
                # å¦‚æœç”Ÿæˆå¤±è´¥ï¼Œä¸å½±å“ä¸»è¦åŠŸèƒ½ï¼Œåªæ˜¯ä¸è¿”å›Markdownæ ¼å¼
        
        if result_type == "chart":
            # ç”ŸæˆEChartsæ ¼å¼çš„spec
            original_chart_config = result.get("chart_config", {})
            data = query_result.get("data", [])
            columns = query_result.get("columns", [])
            
            # æ ¹æ®åŸå§‹é…ç½®ç”ŸæˆEChartsæ ¼å¼çš„spec
            echarts_spec = generate_echarts_spec(original_chart_config, data, columns)
            
            # å¦‚æœæ˜¯è¡¨æ ¼ç±»å‹ï¼Œä½¿ç”¨ç‰¹æ®Šå¤„ç†
            if echarts_spec.get("type") == "table":
                response_data["chart_config"] = {
                    "type": "table",
                    "columns": columns
                }
            else:
                # å›¾è¡¨ç±»å‹ï¼Œè¿”å›å®Œæ•´çš„ECharts specä½œä¸ºconfigï¼Œtypeè®¾ç½®ä¸ºcustomè®©å‰ç«¯ä½¿ç”¨æˆ‘ä»¬çš„spec
                echarts_spec["chart_type"] = "custom"  # æ·»åŠ chart_typeå­—æ®µæ ‡è¯†è¿™æ˜¯EChartsæ ¼å¼
                response_data["chart_config"] = echarts_spec
            
            response_data["data"] = TableData(
                data=data,
                columns=columns
            )
        elif result_type == "table":
            response_data["data"] = TableData(
                data=query_result.get("data", []),
                columns=query_result.get("columns", [])
            )
        else:  # text
            # ç”Ÿæˆæ–‡æœ¬æ‘˜è¦
            data = query_result.get("data", [])
            row_count = len(data)
            columns = query_result.get("columns", [])
            
            summary = f"æŸ¥è¯¢å®Œæˆï¼Œå…± {row_count} æ¡è®°å½•"
            if row_count > 0:
                summary += f"ï¼ŒåŒ…å«å­—æ®µï¼š{', '.join(columns)}"
            
            response_data["data"] = TextData(
                summary=summary,
                details=data[:5] if data else []  # æœ€å¤šæ˜¾ç¤º5æ¡è¯¦ç»†è®°å½•
            )
        
        return DatabaseAnalysisResponse(**response_data)
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"æ•°æ®åº“åˆ†æå¤±è´¥: {str(e)}"
        )


@router.post("/analyze/stream")
async def analyze_database_stream(
    request: DatabaseAnalysisRequest,
    user_info: dict = Depends(GetCurrentUser)
):
    """
    æµå¼æ•°æ®åº“åˆ†ææ¥å£ - è¿”å›åˆ†æè¿‡ç¨‹çš„å®æ—¶è¿›å±•
    """
    async def generate_stream():
        try:
            thread_id = str(uuid4())
            
            # å‘é€å¼€å§‹ä¿¡å·
            yield f"data: {json.dumps({'type': 'start', 'message': 'å¼€å§‹åˆ†ææŸ¥è¯¢...'}, ensure_ascii=False)}\n\n"
            
            # è¿™é‡Œå¯ä»¥å®ç°æµå¼å¤„ç†ï¼Œç›®å‰ç®€åŒ–ä¸ºä¸€æ¬¡æ€§å¤„ç†
            result = await run_database_analysis(
                user_query=request.user_query,
                datasource_id=request.datasource_id,
                table_name=request.table_name,
                thread_id=thread_id
            )
            
            # å‘é€è¿›åº¦æ›´æ–°
            yield f"data: {json.dumps({'type': 'progress', 'message': 'æŸ¥è¯¢åˆ†æå®Œæˆ', 'step': 'analysis'}, ensure_ascii=False)}\n\n"
            
            # å‘é€æœ€ç»ˆç»“æœ
            if result.get("error"):
                yield f"data: {json.dumps({'type': 'error', 'error': result['error']}, ensure_ascii=False)}\n\n"
            else:
                response_data = {
                    "type": "result",
                    "result_type": result.get("result_type", "table"),
                    "data": result.get("query_result", {}),
                    "chart_config": result.get("chart_config"),
                    "metadata": {
                        "sql_query": result.get("sql_query", ""),
                        "execution_time": result.get("query_result", {}).get("execution_time", 0),
                        "row_count": result.get("query_result", {}).get("row_count", 0)
                    }
                }
                yield f"data: {json.dumps(response_data, ensure_ascii=False)}\n\n"
            
            # å‘é€ç»“æŸä¿¡å·
            yield f"data: {json.dumps({'type': 'done'}, ensure_ascii=False)}\n\n"
            
        except Exception as e:
            yield f"data: {json.dumps({'type': 'error', 'error': f'åˆ†æå¤±è´¥: {str(e)}'}, ensure_ascii=False)}\n\n"
    
    return StreamingResponse(
        generate_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "*",
        }
    )


@router.get("/datasources/{datasource_id}/tables")
async def get_tables(
    datasource_id: str,
    user_info: dict = Depends(GetCurrentUser)
):
    """è·å–æ•°æ®æºçš„è¡¨åˆ—è¡¨"""
    try:
        from src.database.models import DataSource
        import pymysql
        
        # è·å–æ•°æ®æºä¿¡æ¯
        datasource = DataSource.GetById(datasource_id)
        if not datasource:
            raise HTTPException(status_code=404, detail=f"æ•°æ®æºä¸å­˜åœ¨: {datasource_id}")
        
        # åˆ›å»ºè¿æ¥
        connection = pymysql.connect(
            host=datasource.host,
            port=datasource.port,
            user=datasource.username,
            password=datasource.password,
            database=datasource.database,
            charset='utf8mb4'
        )
        
        if not connection:
            raise HTTPException(status_code=404, detail=f"æ•°æ®æºä¸å­˜åœ¨: {datasource_id}")
        
        # è·å–è¡¨åˆ—è¡¨
        with connection.cursor() as cursor:
            cursor.execute("SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_TYPE = 'BASE TABLE'")
            result = cursor.fetchall()
            tables = [{"name": row[0], "description": ""} for row in result]
        
        connection.close()
        return {"tables": tables}
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"è·å–è¡¨åˆ—è¡¨å¤±è´¥: {str(e)}"
        ) 